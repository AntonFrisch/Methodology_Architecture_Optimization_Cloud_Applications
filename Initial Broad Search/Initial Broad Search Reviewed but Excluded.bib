@inproceedings{10.1145/3307650.3322227,
author = {Sriraman, Akshitha and Dhanotia, Abhishek and Wenisch, Thomas F.},
title = {SoftSKU: optimizing server architectures for microservice diversity @scale},
year = {2019},
isbn = {9781450366694},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307650.3322227},
doi = {10.1145/3307650.3322227},
abstract = {The variety and complexity of microservices in warehouse-scale data centers has grown precipitously over the last few years to support a growing user base and an evolving product portfolio. Despite accelerating microservice diversity, there is a strong requirement to limit diversity in underlying server hardware to maintain hardware resource fungibility, preserve procurement economies of scale, and curb qualification/test overheads. As such, there is an urgent need for strategies that enable limited server CPU architectures (a.k.a "SKUs") to provide performance and energy efficiency over diverse microservices. To this end, we first undertake a comprehensive characterization of the top seven microservices that run on the compute-optimized data center fleet at Facebook.Our characterization reveals profound diversity in OS and I/O interaction, cache misses, memory bandwidth utilization, instruction mix, and CPU stall behavior. Whereas customizing a CPU SKU for each microservice might be beneficial, it is prohibitive. Instead, we argue for "soft SKUs", wherein we exploit coarse-grain (e.g., boot time) configuration knobs to tune the platform for a particular microservice. We develop a tool, μSKU, that automates search over a soft-SKU design space using A/B testing in production and demonstrate how it can obtain statistically significant gains (up to 7.2\% and 4.5\% performance improvement over stock and production servers, respectively) with no additional hardware requirements.},
booktitle = {Proceedings of the 46th International Symposium on Computer Architecture},
pages = {513–526},
numpages = {14},
keywords = {soft SKU, resource fungibility, microservice},
location = {Phoenix, Arizona},
series = {ISCA '19}
}
@article{EVANGELINOU2018102,
title = {Enterprise applications cloud rightsizing through a joint benchmarking and optimization approach},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {102-114},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X1630512X},
author = {Athanasia Evangelinou and Michele Ciavotta and Danilo Ardagna and Aliki Kopaneli and George Kousiouris and Theodora Varvarigou},
keywords = {Benchmarking, Cloud applications, QoS, Model driven design, Performance prediction, Design space exploration},
abstract = {Migrating an application to the cloud environment requires non-functional properties consideration such as cost, performance and Quality of Service (QoS). Given the variety and the plethora of cloud offerings in addition with the consumption-based pricing models currently available in the cloud market, it is extremely complex to find the optimal deployment that fits the application requirements and provides the best QoS and cost trade-offs. In many cases the performance of these service offerings may vary depending on the congestion level, provider policies and how the application types that are intended to be executed upon them use the computing resources. A key challenge for customers before moving to Cloud is to know application behavior on cloud platforms in order to select the best-suited environment to host their application components in terms of performance and cost. In this paper, we propose a combined methodology and a set of tools that support the design and migration of enterprise applications to Cloud. Our tool chain includes: (i) the performance assessment of cloud services based on cloud benchmark results, (ii) a profiler/classifier mechanism that identifies the computing footprint of an arbitrary application and provides the best matching with a cloud service solution in terms of performance and cost, (iii) and a design space exploration tool, which is effective in identifying the deployment of minimum costs taking into account workload changes and providing QoS guarantees.}
}
@INPROCEEDINGS{7328124,
  author={Heinrich, Robert and Jung, Reiner and Schmieders, Eric and Metzger, Andreas and Hasselbring, Wilhelm and Reussner, Ralf and Pohl, Klaus},
  booktitle={2015 IEEE 9th International Symposium on the Maintenance and Evolution of Service-Oriented and Cloud-Based Environments (MESOCA)}, 
  title={Architectural run-time models for operator-in-the-loop adaptation of cloud applications}, 
  year={2015},
  volume={},
  number={},
  pages={36-40},
  keywords={Adaptation models;Cloud computing;Planning;Privacy;Monitoring},
  doi={10.1109/MESOCA.2015.7328124}}
  @article{10.1145/2897356.2897359,
  author = {Heinrich, Robert},
  title = {Architectural Run-time Models for Performance and Privacy Analysis in Dynamic Cloud Applications},
  year = {2016},
  issue_date = {March 2016},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {43},
  number = {4},
  issn = {0163-5999},
  url = {https://doi.org/10.1145/2897356.2897359},
  doi = {10.1145/2897356.2897359},
  abstract = {Building software systems by composing third-party cloud services promises many benefits such as flexibility and scalability. Yet at the same time, it leads to major challenges like limited control of third party infrastructures and runtime changes which mostly cannot be foreseen during development. While previous research focused on automated adaptation, increased complexity and heterogeneity of cloud services as well as their limited observability, makes evident that we need to allow operators (humans) to engage in the adaptation process. Models are useful for involving humans and conducting analysis, e.g. for performance and privacy. During operation the systems often drifts away from its design-time models. Run-time models are kept insync with the underlying system. However, typical run-time models are close to an implementation level of abstraction which impedes understandability for humans. In this vision paper, we present the iObserve approach to target aforementioned challenges while considering operationlevel adaptation and development-level evolution as two mutual interwoven processes. Central to this perception is an architectural run-time model that is usable for automatized adaptation and is simultaneously comprehensible for humans during evolution. The run-time model builds upon a technology-independent monitoring approach. A correspondence model maintains the semantic relationships between monitoring outcomes and architecture models. As an umbrella a megamodel integrates design-time models, code generation, monitoring, and run-time model update. Currently, iObserve covers the monitoring and analysis phases of the MAPE control loop. We come up with a roadmap to include planning and execution activities in iObserve.},
  journal = {SIGMETRICS Perform. Eval. Rev.},
  month = feb,
  pages = {13–22},
  numpages = {10},
  keywords = {Architectural Run-time Model, Palladio Component Model, Performance Model, Privacy, Usage Profile}
  }
  @article{GESVINDR2020110701,
title = {Architecture design evaluation of PaaS cloud applications using generated prototypes: PaaSArch Cloud Prototyper tool},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110701},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110701},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301485},
author = {David Gesvindr and Ondrej Gasior and Barbora Buhnova},
keywords = {Cloud computing, Software architecture design, Prototype generation, Quality evaluation, Performance, Internet of things},
abstract = {Platform as a Service (PaaS) cloud domain brings great benefits of an elastic platform with many prefabricated services, but at the same time challenges software architects who need to navigate a rich set of services, variability of PaaS cloud environment and quality conflicts in existing design tactics, which makes it almost impossible to foresee the impact of architectural design decisions on the overall application quality without time-consuming implementation of application prototypes. To ease the architecture design of PaaS cloud applications, this paper proposes a design-time quality evaluation approach for PaaS cloud applications based on automatically generated prototypes, which are deployed to the cloud and repeatedly evaluated in the context of multiple quality attributes and environment configurations. In this paper, all steps of the approach are described and demonstrated on an example of a real-world complex IoT system for collection and processing of Smart Home sensor data. The approach has been implemented and the automated prototype generation and evaluation tool, referred to as PaaSArch Cloud Prototyper, is presented together with the approach.}
}
@INPROCEEDINGS{7167407,
  author={Casale, Giuliano and Ardagna, Danilo and Artac, Matej and Barbier, Franck and Di Nitto, Elisabetta and Henry, Alexis and Iuhasz, Gabriel and Joubert, Christophe and Merseguer, Jose and Munteanu, Victor Ion and Perez, Juan Fernando and Petcu, Dana and Rossi, Matteo and Sheridan, Craig and Spais, Ilias and Vladuic, Daniel},
  booktitle={2015 IEEE/ACM 7th International Workshop on Modeling in Software Engineering}, 
  title={DICE: Quality-Driven Development of Data-Intensive Cloud Applications}, 
  year={2015},
  volume={},
  number={},
  pages={78-83},
  keywords={Unified modeling language;Big data;Data models;Computational modeling;Analytical models;Reliability;Software;Big Data;quality assurance;model-driven engineering},
  doi={10.1109/MiSE.2015.21}}
  @INPROCEEDINGS{7930196,
  author={Gesvindr, David and Buhnova, Barbora and Gasior, Ondrej},
  booktitle={2017 IEEE International Conference on Software Architecture (ICSA)}, 
  title={Quality Evaluation of PaaS Cloud Application Design Using Generated Prototypes}, 
  year={2017},
  volume={},
  number={},
  pages={31-40},
  keywords={Cloud computing;Unified modeling language;Prototypes;Tools;Google;Computational modeling;Platform as a Service cloud;Software Architecture Design;Quality Evaluation;Generated Application Prototypes},
  doi={10.1109/ICSA.2017.43}}
  @article{evangelinou2015joint,
  title={A joint benchmark-analytic approach for design-time assessment of multi-cloud applications},
  author={Evangelinou, Athanasia and Ciavotta, Michele and Kousiouris, George and Ardagna, Danilo},
  journal={Procedia Computer Science},
  volume={68},
  pages={67--77},
  year={2015},
  publisher={Elsevier}
}
@inproceedings{franceschelli2013space4cloud,
  title={Space4cloud: A tool for system performance and costevaluation of cloud systems},
  author={Franceschelli, Davide and Ardagna, Danilo and Ciavotta, Michele and Di Nitto, Elisabetta},
  booktitle={Proceedings of the 2013 international workshop on Multi-cloud applications and federated clouds},
  pages={27--34},
  year={2013}
}