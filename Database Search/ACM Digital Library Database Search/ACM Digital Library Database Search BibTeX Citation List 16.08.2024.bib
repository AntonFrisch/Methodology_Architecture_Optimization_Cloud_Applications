@inproceedings{10.1145/3603273.3631191,
author = {Tang, Zhu and Cui, YiChuan and Peng, SiYong and Dai, GuangHua and Yang, JianJun and Duan, YanHong},
title = {Research on the Design of Sensor Intelligent Defense System},
year = {2024},
isbn = {9798400708268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603273.3631191},
doi = {10.1145/3603273.3631191},
abstract = {This paper analyzes the necessity of building an intelligent defense system for sensors, systematically designs the intelligent defense system from three aspects: hardware composition, Software architecture and information flow interaction, and puts forward six key support technologies for system design, namely, integrated management and control technology, Internet of Things technology, Big data and cloud computing technology, artificial intelligence technology, intelligent planning technology, and auxiliary decision-making technology, which have important application value.},
booktitle = {Proceedings of the 2023 International Conference on Advances in Artificial Intelligence and Applications},
pages = {354–358},
numpages = {5},
keywords = {intelligent defense, sensor, system design},
location = {Wuhan, China},
series = {AAIA '23}
}

@inproceedings{10.1145/3647782.3647811,
author = {Insuasti, Efrain and Cisneros, Bryan and Morillo, Paulina},
title = {A Software Architecture Design Based on Microservices for an E-wallet in Ecuador},
year = {2024},
isbn = {9798400716652},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647782.3647811},
doi = {10.1145/3647782.3647811},
abstract = {The use of payment apps, also known as mobile wallets, has increased worldwide in recent years, especially after the COVID-19 pandemic. However, in Latin America, implementing this technology still faces challenges associated with the regulation of FinTech, the accessibility of services, and the security of information. In the case of Ecuador, there are some mobile wallet proposals, but they still have restrictions on carrying out different types of financial transactions. A software architecture design for a mobile wallet that promotes inclusion and equality in access to financial services is proposed to address these challenges. The design uses microservices architecture and cloud computing design patterns to give it greater robustness, adaptability, and capacity, offering a better user experience and driving the development of new features. This paper also examines the current legal and regulatory framework for electronic payment systems in Ecuador, and these legal aspects were considered in the design. The technical requirements for building this software architecture, including its interactions and functionalities, are also discussed.},
booktitle = {Proceedings of the 2024 7th International Conference on Computers in Management and Business},
pages = {185–192},
numpages = {8},
keywords = {AWS, Cloud Computing, E-Payments, Financial Regulation, Mobile Payments},
location = {Singapore, Singapore},
series = {ICCMB '24}
}

@inproceedings{10.1145/3643660.3643942,
author = {Eisenreich, Tobias and Speth, Sandro and Wagner, Stefan},
title = {From Requirements to Architecture: An AI-Based Journey to Semi-Automatically Generate Software Architectures},
year = {2024},
isbn = {9798400705632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643660.3643942},
doi = {10.1145/3643660.3643942},
abstract = {Designing domain models and software architectures represents a significant challenge in software development, as the resulting architectures play a vital role in fulfilling the system's quality of service. Due to time pressure, architects often model only one architecture based on their known limited domain understanding, patterns, and experience instead of thoroughly analyzing the domain and evaluating multiple candidates, selecting the best fitting. Existing approaches try to generate domain models based on requirements, but still require time-consuming manual effort to achieve good results. Therefore, in this vision paper, we propose a method to generate software architecture candidates semi-automatically based on requirements using artificial intelligence techniques. We further envision an automatic evaluation and trade-off analysis of the generated architecture candidates using, e.g., the architecture trade-off analysis method combined with large language models and quantitative analyses. To evaluate this approach, we aim to analyze the quality of the generated architecture models and the efficiency and effectiveness of our proposed process by conducting qualitative studies.},
booktitle = {Proceedings of the 1st International Workshop on Designing Software},
pages = {52–55},
numpages = {4},
keywords = {requirements, software architecture, architecture evaluation, LLM},
location = {Lisbon, Portugal},
series = {Designing '24}
}

@inproceedings{10.1145/3622748.3622749,
author = {Oliveira, Manoel Marisergio Alves de and Lima, Rian Carlos Silva and Costa, Marcos Vinicius Lima da and Trindade, Cl\'{a}udio Silva and Queiroz, Paulo Gabriel Gadelha},
title = {SPL integrated with Microservices: a hybrid architectural proposal for multitenant SaaS},
year = {2023},
isbn = {9798400709524},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3622748.3622749},
doi = {10.1145/3622748.3622749},
abstract = {Designing systems to serve a large number of people, who have similar demands, but also have varied needs and generate a huge volume of data, requires a software architecture that allows constant evolution, is easy to maintain, and has the ability to scale smartly. The SPL technique with microservices architecture seems promising to meet these requirements, but this integration is not trivial. Thus, we conduct a SLR that identified 3 architectures that proposed the combination of these techniques. However, the architectures found were complex and reduced time-to-market, as they proposed the implementation of all resources through microservices. Thus, in order to reduce the complexity of development and, consequently, reduce the time to market, this work presents a proposal for the design of a hybrid SPL architecture, through the combination of large backend APIs and microservices. In addition, this research paper presents a case study that consisted of defining the architecture of a medical clinics SPL as a Multi-tenant Software as a Service. Finally, we compare the complexity of the architecture generated using our approach, with a microservice architecture constructed using other approach found in literature.},
booktitle = {Proceedings of the 17th Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {1–10},
numpages = {10},
keywords = {SaaS Multilocat\'{a}rio, Microsservi\c{c}o, Linha de Produto de Software, Arquitetura de Software},
location = {Campo Grande, Brazil},
series = {SBCARS '23}
}

@inproceedings{10.1145/3450569.3464395,
author = {Al Lail, Mustafa},
title = {Poster: Towards Cloud-Based Software for Incorporating Time and Location into Access Control Decisions},
year = {2021},
isbn = {9781450383653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3450569.3464395},
doi = {10.1145/3450569.3464395},
abstract = {The increasing dependency on cloud computing has drawn attention to the security weaknesses of cloud providers. Not only how information is accessed, but also where and when have become important considerations in cloud security. Certain situations exist where it is necessary to restrict access to cloud resources based on time and location. An example is a policy for a medical institution where doctors can only access patient records at hospitals during their shifts. The Generalized Spatio-Temporal Role-Based Access Control model (GSTRBAC) determines users' access to resources based on such information. This poster proposes a cloud-based software architecture and outlines it possible implementation of the GSTRBAC model.},
booktitle = {Proceedings of the 26th ACM Symposium on Access Control Models and Technologies},
pages = {55–57},
numpages = {3},
keywords = {access control, authorization, location, software, time},
location = {Virtual Event, Spain},
series = {SACMAT '21}
}

@article{10.1145/3474058,
author = {Mbongue, Joel Mandebi and Kwadjo, Danielle Tchuinkou and Shuping, Alex and Bobda, Christophe},
title = {Deploying Multi-tenant FPGAs within Linux-based Cloud Infrastructure},
year = {2021},
issue_date = {June 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {1936-7406},
url = {https://doi.org/10.1145/3474058},
doi = {10.1145/3474058},
abstract = {Cloud deployments now increasingly exploit Field-Programmable Gate Array (FPGA) accelerators as part of virtual instances. While cloud FPGAs are still essentially single-tenant, the growing demand for efficient hardware acceleration paves the way to FPGA multi-tenancy. It then becomes necessary to explore architectures, design flows, and resource management features that aim at exposing multi-tenant FPGAs to the cloud users. In this article, we discuss a hardware/software architecture that supports provisioning space-shared FPGAs in Kernel-based Virtual Machine (KVM) clouds. The proposed hardware/software architecture introduces an FPGA organization that improves hardware consolidation and support hardware elasticity with minimal data movement overhead. It also relies on VirtIO to decrease communication latency between hardware and software domains. Prototyping the proposed architecture with a Virtex UltraScale+ FPGA demonstrated near specification maximum frequency for on-chip data movement and high throughput in virtual instance access to hardware accelerators. We demonstrate similar performance compared to single-tenant deployment while increasing FPGA utilization, which is one of the goals of virtualization. Overall, our FPGA design achieved about 2\texttimes{} higher maximum frequency than the state of the art and a bandwidth reaching up to 28 Gbps on 32-bit data width.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = dec,
articleno = {19},
numpages = {31},
keywords = {KVM, virtualization, network-on-chip, multi-tenancy, FPGA, Cloud}
}

@inproceedings{10.1145/3594671.3594688,
author = {Miszczak, Jaros\l{}aw Adam},
title = {Symbolic Quantum Programming for Supporting Applications of Quantum Computing Technologies},
year = {2023},
isbn = {9798400707551},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594671.3594688},
doi = {10.1145/3594671.3594688},
abstract = {The goal of this paper is to deliver the overview of the current state of the art, provide experience report on developing quantum software tools, and outline the perspective for developing quantum programming tools supporting symbolic programming for the needs of quantum computing technologies. The main focus of this paper is on quantum computing technologies, as they can in the most direct way benefit from developing tools enabling the symbolic manipulation of quantum circuits and providing software tools for creating, optimizing, and testing quantum programs. We deliver a short survey of the most popular approaches in the field of quantum software development, pointing their strengths and weaknesses. This helps to formulate a list of desirable characteristics which should be included in quantum computing frameworks. Next, we describe a software architecture and its preliminary implementation supporting the development of quantum programs using symbolic approach, encouraging the functional programming paradigm, and, at the same, time enabling the integration with high-performance and cloud computing. The described software consists of several packages developed to address different needs, but nevertheless sharing common design concepts. We also outline how the presented approach could be used in tasks in quantum software engineering: quantum software testing and quantum circuit construction.},
booktitle = {Companion Proceedings of the 7th International Conference on the Art, Science, and Engineering of Programming},
pages = {101–108},
numpages = {8},
keywords = {symbolic manipulation, quantum technologies, quantum computing, functional programming, computer algebra},
location = {Tokyo, Japan},
series = {Programming '23}
}

@article{10.1145/3593227,
author = {Alipour, Mina and Moghaddam, Mahyar T. and Vaidhyanathan, Karthik and Kj\ae{}rgaard, Mikkel Baun},
title = {Emoticontrol: Emotions-based Control of User-Interfaces Adaptations},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {EICS},
url = {https://doi.org/10.1145/3593227},
doi = {10.1145/3593227},
abstract = {Emotions are integral to human nature, and their existence, duration, and evolution could lead to specific behaviors. If emotions and behaviors are ignored in the design of socio-technical systems, they will fail or cause discomfort. User interfaces (UIs) are elements of interactive systems able to trigger or moderate emotions. UIs are increasingly designed adaptive to users' various characteristics, intending to improve their satisfaction, performance, and decisions. However, previous adaptation supervising approaches are not effectively adopted in real life since they neglect the dynamic behaviors of humans or systems. This paper proposes Emoticontrol, a quality-driven approach to adapting UIs to users' emotions using Model-Free Reinforcement Learning (MFRL). The approach aims to maximize applying the essential adaptations and minimize the unnecessary ones towards users' enhanced quality of experience (QoE). The approach also considers improving the software quality of service (QoS) by designing software architecture alternatives. We chose emergency evacuation training as a suitable evaluation domain since people experience intense emotions in potential danger. We performed experiments with a mobile application we developed that acts as a recommender system in evacuation training. By taking contextual input of the users' basic emotions from face recognition, the application intelligently adapts its UI to quickly lead people to safe areas while keeping them emotionally controlled. We consider software performance a crucial QoS; thus, we adopt and test architectures that facilitate an acceptable level of performance. The evaluation process confirms the efficiency and effectiveness of the MFRL in iterations, as well as compared to other UI adaptation techniques.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = jun,
articleno = {175},
numpages = {29},
keywords = {user interface, self-adaptation, reinforcement learning, emotions, emergency}
}

@inproceedings{10.1145/3452383.3452385,
author = {Dasgupta, Gargi B.},
title = {AI and its Applications in the Cloud strategy},
year = {2021},
isbn = {9781450390460},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3452383.3452385},
doi = {10.1145/3452383.3452385},
abstract = {The fourth industrial revolution identifies cloud computing, data, and artificial intelligence (AI) as opportunity clusters with double digit growth in the next couple of years. As part of the cloud and digital transformation, the role of AI is crucial in enabling that transformation as well as creating the new breed of applications on top. AI mechanisms can help accelerate the modernization of applications, their management, and the testing on cloud architectures. I will focus on two sub-problems: 1) Refactoring of massive monolith applications using AI techniques. This problem statement is particularly relevant in understanding legacy un-optimized code and transforming them to be more cloud-ready. Microservices are indeed becoming the de-facto design choice for software architecture. It involves partitioning the software components into finer modules such that the development can happen independently [2]. It also provides natural benefits when deployed on the cloud since resources can be allocated dynamically to necessary components based on demand. We are exploring how AI can help accelerate the transformation of existing applications to microservices. 2) Detecting faults in application behavior at runtime from operational data. This problem statement is particularly relevant in understanding how to manage this new architecture of multiple microservices across the cloud stack [1], [3]. Operational data artifacts span across logs, metrics, tickets, and traces. Looking at signals across the artifacts and across the stack presents a challenging data correlation problem. AI mechanisms can help accelerate problem determination in these complex environments. I will also share my thoughts on how fundamental breakthroughs in AI Research will be needed as we address some of the core problems of cloud computing.},
booktitle = {Proceedings of the 14th Innovations in Software Engineering Conference (Formerly Known as India Software Engineering Conference)},
articleno = {2},
numpages = {1},
keywords = {AI Ops, code refactoring, hybrid cloud, log anomalies, modernization},
location = {Bhubaneswar, Odisha, India},
series = {ISEC '21}
}

@inproceedings{10.1145/3501774.3501780,
author = {Gravanis, Dimitrios and Kakarontzas, George and Gerogiannis, Vassilis},
title = {You don't need a Microservices Architecture (yet): Monoliths may do the trick},
year = {2022},
isbn = {9781450385060},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3501774.3501780},
doi = {10.1145/3501774.3501780},
abstract = {Within the past decade, the advent of cloud computing in terms of infrastructure, technology stacks, availability of services and tooling, along with the gradual improvement of its market environment, has driven many organizations to either consider or migrate many existing software systems to the cloud, either fully or partially. A common predicament in most cases, is the existence of a complex, monolithic application, potentially considered legacy at the time, that was not designed to be cloud-native and therefore requires a degree of redesign/reimplementation in order to benefit from cloud deployment. In such cases, the decomposition of the monolith to a set of loosely coupled, highly cohesive and self-contained microservices is a valid recommendation, provided that the organization is prepared to withstand the additional cost, in terms of human and financial resources, along with the unavoidable development overhead, which is inevitable during the early stages. However, the tendency of the tech world to embrace new trends and jump on hype trains for fear of obsoletion, has led to an excessive adoption of the microservices architecture (MSA), even in cases where such an architecture is not viable for the organization, or does not derive from any business requirements. This research focuses on establishing the position of a traditional monolith in the modern software architecture landscape and determine use cases that can still benefit from this paradigm, as well as use cases that could benefit from a partial or full transition to microservices architectures instead.},
booktitle = {Proceedings of the 2021 European Symposium on Software Engineering},
pages = {39–44},
numpages = {6},
keywords = {Software Industry, Monolithic Architecture, Migration, Microservices Architecture},
location = {Larissa, Greece},
series = {ESSE '21}
}

@inproceedings{10.1145/3171592.3171613,
author = {Bin, Wang and Shulin, Yang and Xuelei, Ren and Guyang, Wang},
title = {Research on Digital Publishing Application System Based on Micro-Service Architecture},
year = {2017},
isbn = {9781450353663},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3171592.3171613},
doi = {10.1145/3171592.3171613},
abstract = {Micro-service architecture technology is an epoch-making technology in the Internet field, providing a good solution for the lack of traditional back-office architecture. This paper analyzes the key technologies of micro service architecture, especially the use of Docker container technology, and introduces micro service architecture technology into digital publishing industry, analyzes some existing problems in traditional digital publishing industry, and then analyzes the micro service architecture Technology in the digital publishing application of the two main aspects, one is the digital publishing system architecture optimization, and second, digital publishing production process improvement. Which provides some reference for the traditional digital publishing field transformation.},
booktitle = {Proceedings of the 2017 VI International Conference on Network, Communication and Computing},
pages = {140–144},
numpages = {5},
keywords = {docker, digital publishing, architecture, Micro-service},
location = {Kunming, China},
series = {ICNCC '17}
}

@inproceedings{10.1145/3671016.3674817,
author = {Chen, Geng and Li, Chenlin and Tyszberowicz, Shmuel and Liu, Zhiming and Liu, Bo},
title = {Mono2MS: Deep Fusion of Multi-Source Features for Partitioning Monolith into Microservices},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671016.3674817},
doi = {10.1145/3671016.3674817},
abstract = {Microservice architecture is favoured for its significant scalability, independent evolution, and advantages in performance elasticity. Partitioning a monolith into microservices has become a pivotal issue in software architecture refactoring. Concurrently, assessing the quality of such partitioning also presents a significant challenge. To address this problem, we propose a solution that (1) proposes a method for extracting and representing the multi-source features such as semantics, functionality, and performance of monolithic systems; (2) designs a deep fusion graph clustering model for partitioning a monolith into microservices intelligently; and (3) establishes a comprehensive set of assessment metrics to quantify the quality of the partitioning suggestion. We conducted experiments and analyses on five benchmark projects. By comparing our approach with six other methods, we have demonstrated the advantages of our methodology. Furthermore, ablating different modules has validated the effectiveness of our proposed monolith features analysis and deep fusion graph clustering model.},
booktitle = {Proceedings of the 15th Asia-Pacific Symposium on Internetware},
pages = {259–268},
numpages = {10},
keywords = {deep graph clustering, graph neural network, microservice, monolith partitioning},
location = {Macau, China},
series = {Internetware '24}
}

@inproceedings{10.1145/2938559.2948790,
author = {Ra, Ho-Kyeong and Yoon, Hee Jung and Salekin, Asif and Lee, Jin-Hee and Stankovic, John A. and Son, Sang Hyuk},
title = {Poster: Software Architecture for Efficiently Designing Cloud Applications using Node.js},
year = {2016},
isbn = {9781450344166},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2938559.2948790},
doi = {10.1145/2938559.2948790},
abstract = {We propose a practical solution for cloud application development using Node.js and Express library by presenting: (1) a software architecture which utilizes two standard inheritance pattern techniques, the top-down and divide and conquer approaches, to effectively organize the structure of the application for improved maintainability and extensibility in the long-run, and (2) an easy-to-follow guideline that instructs the implementation procedures for developing Node.js cloud applications.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services Companion},
pages = {72},
numpages = {1},
keywords = {software architecture, node.js, cloud applications},
location = {Singapore, Singapore},
series = {MobiSys '16 Companion}
}

@proceedings{10.1145/2737182,
title = {QoSA '15: Proceedings of the 11th International ACM SIGSOFT Conference on Quality of Software Architectures},
year = {2015},
isbn = {9781450334709},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 11th International ACM Sigsoft Conference on the Quality of Software Architectures -- QoSA 2015. For more than a decade, QoSA has strived to advance the state of the art of quality aspects of software architecture, focusing broadly on its quality characteristics and how these relate to the design of software architectures. Specific issues of interest are defining and modeling quality measures, evaluating and managing architecture quality, linking architecture to requirements and implementation, and preserving architecture quality throughout the system lifetime. Past themes for QoSA include Architecting for Adaptivity (2014), The System View (2013), Evolving Architectures (2012), Quality throughout the Software Lifecycle (2011), and Research into Practice -- Reality and Gaps (2010).QoSA 2015's theme is "Software Architecture for the 4th Industrial Revolution". After mechanization, mass production, and electronics, the Internet is about to enable a new level of productivity in manufacturing. This shall be enabled by smart cyber-physical systems connected to cloud computing services and communicating using standardized semantics. In the near future, industrial big data analytics on monitored sensor data shall improve the efficiency and individualization of production facilities. This year's QoSA conference solicited contributions that explore the various implications of this upcoming industrial revolution on software architecture. This included reference architectures, software architectures adapting at run time, architecture styles and patterns for cyber-physical and distributed systems.The call for papers attracted 42 initial submissions from Asia, North America, Africa, and Europe and 28 final submissions were considered during the review process. The program committee accepted 11 full papers and 2 short papers that cover topics, such as new architecture modeling approaches, architectural tactics for mobile computing, cloud computing architectures, and cyberphysical systems. QoSA's 2015 proceedings also include 2 papers from the WCOP 2015, the 20th International Doctoral Symposium on Components and Architecture.QoSA 2015 is part of the federated events on component-based software engineering and software architecture (CompArch 2015), which include WICSA 2015 (12th Working IEEE / IFIP Conference on Software Architecture) and CBSE 2015 (18th International ACM SIGSOFT Symposium on Component-Based Software Engineering).},
location = {Montr\'{e}al, QC, Canada}
}

@inproceedings{10.1145/2851613.2852014,
author = {Nocera, Francesco},
title = {Fuzzy ontology-driven web-based framework for supporting architectural design: student research abstract},
year = {2016},
isbn = {9781450337397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851613.2852014},
doi = {10.1145/2851613.2852014},
abstract = {Since 2005 when Anton Jansen and Jan Bosch [3] gave a modern definition of Software Architecture as a composition of a set of explicit design decisions, a new perspective concerning software architectures design decisions, quality and goals evaluations have been dominating the scientific literature in this field. Designing the software architecture of non-trivial systems belonging to several application domains, namely industrial automation, defense telecommunication, financial services, and so on, is not an easy task, and requires highly skilled and experienced people. Beyond these, new challenges in the design and in architectural models are derived from self-managing and self-adaptive capabilities that are typical of many modern and emerging software systems, including the industrial Internet of Things, cyber-physical systems, cloud computing, and mobile computing. The satisfaction of quality requirements and the appropriate options for future changes are among the major goals of software architectures. In defining and modeling software architecture through patterns, a challenging issue is also concerned with the number of different available decisions depending on the fact that patterns can cooperate, are composable, are complementary or exclusive with respect to a given problem.},
booktitle = {Proceedings of the 31st Annual ACM Symposium on Applied Computing},
pages = {1361–1362},
numpages = {2},
location = {Pisa, Italy},
series = {SAC '16}
}

@inproceedings{10.1145/3266237.3266247,
author = {Ferreira, Tha\'{\i}s and Viana, Davi and Fernandes, Juliana and Santos, Rodrigo},
title = {Identifying emerging topics and difficulties in software engineering education in Brazil},
year = {2018},
isbn = {9781450365031},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3266237.3266247},
doi = {10.1145/3266237.3266247},
abstract = {Technological evolution has contributed to the emergence of new paradigms and trends that meet demands of a dynamic market. In this context, teaching software engineering (SE) becomes a challenge. SE professors in turn seek strategies to prepare students for dealing with industry's demands. Therefore, it is important to know how emerging SE topics has affected the teaching-learning process. This paper aims to identify the emerging SE topics in undergraduate courses in the Brazilian scenario and difficulties in its teaching-learning process. A survey with SE professors was carried out and allowed us to identify a set of emerging topics explored in Brazilian SE courses as well as underlying difficulties in the teaching-learning process. Qualitative analysis was applied. Some topics identified from the dataset were agile methods, reuse, software architecture, software product lines, SE for software as a service, SE for startups, among others. Relations between such emerging topics and difficulties regarding pedagogy, materials, students and content were identified as well.},
booktitle = {Proceedings of the XXXII Brazilian Symposium on Software Engineering},
pages = {230–239},
numpages = {10},
keywords = {survey, software engineering, education},
location = {Sao Carlos, Brazil},
series = {SBES '18}
}

@inproceedings{10.1145/3106237.3117767,
author = {Adzic, Gojko and Chatley, Robert},
title = {Serverless computing: economic and architectural impact},
year = {2017},
isbn = {9781450351058},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3106237.3117767},
doi = {10.1145/3106237.3117767},
abstract = {Amazon Web Services unveiled their "Lambda" platform in late 2014. Since then, each of the major cloud computing infrastructure providers has released services supporting a similar style of deployment and operation, where rather than deploying and running monolithic services, or dedicated virtual machines, users are able to deploy individual functions, and pay only for the time that their code is actually executing. These technologies are gathered together under the marketing term "serverless" and the providers suggest that they have the potential to significantly change how client/server applications are designed, developed and operated. This paper presents two case industrial studies of early adopters, showing how migrating an application to the Lambda deployment architecture reduced hosting costs - by between 66\% and 95\% - and discusses how further adoption of this trend might influence common software architecture design practices.},
booktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},
pages = {884–889},
numpages = {6},
keywords = {Serverless, Economics, Cloud Computing},
location = {Paderborn, Germany},
series = {ESEC/FSE 2017}
}

@inproceedings{10.1145/3589608.3594742,
author = {Meadows, Catherine and Hounsinou, Sena and Wood, Timothy and Bloom, Gedare},
title = {Sidecar-based Path-aware Security for Microservices},
year = {2023},
isbn = {9798400701733},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589608.3594742},
doi = {10.1145/3589608.3594742},
abstract = {Microservice architectures decompose web applications into loosely-coupled, distributed components that interact with each other to provide an overall service. While this popular software architecture paradigm has many advantages in development and deployment, it also introduces a wider attack surface that is vulnerable to both internal and external attackers. Potentially malicious third-party services or software packages, as well as increased communication endpoints, introduce a wide array of security concerns. To improve the resiliency of microservice-based applications, many of which store sensitive data, we propose a novel, path-based anomaly detection and access control infrastructure that requires no modifications to existing software. We propose leveraging trusted proxies deployed alongside each service for request inspection, anomaly detection and signed token propagation for end-user path validation. Our approach reduces the trusted computing base away from the microservices to a smaller set of components that allow for less trust and a smaller attack surface.},
booktitle = {Proceedings of the 28th ACM Symposium on Access Control Models and Technologies},
pages = {157–162},
numpages = {6},
keywords = {microservice security, node.js, service-oriented architecture},
location = {Trento, Italy},
series = {SACMAT '23}
}

@inproceedings{10.5555/2735522.2735530,
author = {Hamdaqa, Mohammad and Tahvildari, Ladan},
title = {The (5+1) architectural view model for cloud applications},
year = {2014},
publisher = {IBM Corp.},
address = {USA},
abstract = {Existing software architecture frameworks focus on application development, rather than the dynamic evolution of applications at runtime. Their view models reflect design considerations, more than service operations. However, the quality of a cloud application depends on its configuration and the architecture of its service model. For this reason, we need a view model that is constructed around deployment. This paper proposes a (5+1) architectural view model, where each view corresponds to a different perspective on cloud application deployment. The (5+1) view model has been realized as a layered, domain specific modeling language, and the capabilities of this language have been illustrated using a representative domain example. The model was derived by investigating the process of architecting cloud applications, and then providing a set of meta-models to describe cloud applications within their ecosystem.},
booktitle = {Proceedings of 24th Annual International Conference on Computer Science and Software Engineering},
pages = {46–60},
numpages = {15},
location = {Markham, Ontario, Canada},
series = {CASCON '14}
}

@article{10.5555/2752981.2752999,
author = {Cox, Crystal and Murphy, Michael A.},
title = {Hands-on, web service based, software architecture lab component for software engineering course},
year = {2015},
issue_date = {May 2015},
publisher = {Consortium for Computing Sciences in Colleges},
address = {Evansville, IN, USA},
volume = {30},
number = {5},
issn = {1937-4771},
abstract = {This paper describes a lab series component for learning multi-layer, web service based software architecture in an online, hybrid, or traditional format software engineering course. The labs complement the software engineering process and theory course topics with practical experience using current industry standard tools and technologies. No central infrastructure is required; students build the development/test environment from the ground up using free and widely used software, such as Apache Tomcat, Java, Jersey, and MySQL on a virtual machine. Survey results show that students see the labs as a valuable learning experience.},
journal = {J. Comput. Sci. Coll.},
month = may,
pages = {74–80},
numpages = {7}
}

@inproceedings{10.1145/1851476.1851485,
author = {Chapman, Clovis and Emmerich, Wolfgang and M\'{a}rquez, Ferm\'{\i}n Gal\'{a}n and Clayman, Stuart and Galis, Alex},
title = {Software architecture definition for on-demand cloud provisioning},
year = {2010},
isbn = {9781605589428},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1851476.1851485},
doi = {10.1145/1851476.1851485},
abstract = {Cloud computing [23] is a promising paradigm for the provisioning of IT services. Cloud computing infrastructures, such as those offered by the RESERVOIR project, aim to facilitate the deployment, management and execution of services across multiple physical locations in a seamless manner. In order for service providers to meet their quality of service objectives, it is important to examine how software architectures can be described to take full advantage of the capabilities introduced by such platforms. When dealing with software systems involving numerous loosely coupled components, architectural constraints need to be made explicit to ensure continuous operation when allocating and migrating services from one host in the Cloud to another. In addition, the need for optimising resources and minimising over-provisioning requires service providers to control the dynamic adjustment of capacity throughout the entire service lifecycle. We discuss the implications for software architecture definitions of distributed applications that are to be deployed on Clouds. In particular, we identify novel primitives to support service elasticity, co-location and other requirements, propose language abstractions for these primitives and define their behavioural semantics precisely by establishing constraints on the relationship between architecture definitions and Cloud management infrastructures using a model denotational approach in order to derive appropriate service management cycles.},
booktitle = {Proceedings of the 19th ACM International Symposium on High Performance Distributed Computing},
pages = {61–72},
numpages = {12},
keywords = {software architecture, service definition, cloud computing},
location = {Chicago, Illinois},
series = {HPDC '10}
}

@inproceedings{10.1109/SEH.2019.00019,
author = {M\'{a}rquez, Gast\'{o}n and Astudillo, Hern\'{a}n and Taramasco, Carla},
title = {Exploring security issues in telehealth systems},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SEH.2019.00019},
doi = {10.1109/SEH.2019.00019},
abstract = {Telehealth systems (TS's) provide remote health-based services to improve the quality of service of patient treatment. Most healthcare professionals have access to standard telecommunications technology (such as Wireless Body Area Network (WBAN), biosensors, remote medical robots, and others) to offer remote care of elderly and physically less able patients as well as remote surgeries, treatments, and diagnoses. In order to ensure the functionality of TS's, several systemic properties must be satisfied, including security. Although there are studies that discuss different security approaches in TS's, it is difficult to have a clear view of existing security issues and solutions for these systems. In this article, a systematic mapping study was performed to detect, organize and characterize security issues in TS's. We identified 41 studies which were classified according to their research strategy, target problem, security issue addressed, and proposals. Results reveal that (i) 4 security issues were identified; (ii) 3 strategies were distinguished to handle security issues; (iii) patient and wireless medical data are the most affected medical supplies. Security in TS's reveals diverse challenges that concern Software Engineering. Areas such as requirements, software architecture, and security patterns play an important role in order to handle security issues.},
booktitle = {Proceedings of the 1st International Workshop on Software Engineering for Healthcare},
pages = {65–72},
numpages = {8},
keywords = {telehealth systems, telehealth, software engineering},
location = {Montreal, Quebec, Canada},
series = {SEH '19}
}

@inproceedings{10.1145/3241403.3241407,
author = {Truong, Hong-Linh and Gao, Lingfan and Hammerer, Michael},
title = {Service architectures and dynamic solutions for interoperability of IoT, network functions and cloud resources},
year = {2018},
isbn = {9781450364836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3241403.3241407},
doi = {10.1145/3241403.3241407},
abstract = {Within an IoT Cloud application, various subsystems and layers of IoT, edge and cloud infrastructures are involved and we need to make sure that the involved components and data are interoperable w.r.t. data models, protocols and access policies. Such requirements must be addressed by IoT Cloud applications and platforms. Furthermore, such requirements often need to be fulfilled at runtime. Tackling such requirements requires huge effort in software development tasks to ensure interoperable interfaces, protocols and data. At runtime, it is also extremely challenging to orchestrate and configure software services for interoperability under elastic demands. In this work, we show our rsiHub toolset which allows to dynamically provision resource slices of IoT, network functions and cloud services that are interoperable for requirements from IoT Cloud applications. We combine various software architecture models and designs with runtime techniques to leverage diverse types of metadata, software services, and data processing functions to enable and simplify interoperability tasks for IoT Cloud developers and users. We will demonstrate the rsiHub framework together with IoTCloudSamples to show how our toolset will substantially simplify effort in building complex interoperable IoT Cloud designs through several real world examples.},
booktitle = {Proceedings of the 12th European Conference on Software Architecture: Companion Proceedings},
articleno = {2},
numpages = {4},
keywords = {resource slice, provisioning, interoperability, cloud, IoT},
location = {Madrid, Spain},
series = {ECSA '18}
}

@inproceedings{10.1109/ICSE-COMPANION.2009.5071055,
author = {Lago, Patricia and Avgeriou, Paris and Kruchten, Philippe},
title = {Fourth international workshop on sharing and reusing architectural knowledge (SHARK 2009)},
year = {2009},
isbn = {9781424434954},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/ICSE-COMPANION.2009.5071055},
doi = {10.1109/ICSE-COMPANION.2009.5071055},
abstract = {Architectural knowledge has been recognized by the software architecture community as a self-contained research area in software architecture, and brought along some promising research directions. In this workshop we discuss the issues that lead to the application of architectural knowledge in research and industrial practice, ongoing research and new ideas to advance the field. In its previous editions this workshop examined the state of the art and practice, future challenges and trends, and architectural knowledge as perceived by different research communities, including requirements engineering, service-oriented computing and international standardization. This fourth edition will discuss, among others, the application, experimentation, specialization and use of architectural knowledge theory and approaches.},
booktitle = {Proceedings of the 2009 31st International Conference on Software Engineering: Companion Volume},
pages = {447–448},
numpages = {2},
series = {ICSE '09 COMPANION}
}

@inproceedings{10.1145/1985793.1986043,
author = {Mattmann, Chris A. and Medvidovic, Nenad and Mohan, T. S. and O'Malley, Owen},
title = {Workshop on software engineering for cloud computing (SECLOUD 2011)},
year = {2011},
isbn = {9781450304450},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1985793.1986043},
doi = {10.1145/1985793.1986043},
abstract = {Cloud computing is emerging as more than simply a technology platform but a software engineering paradigm for the future. Hordes of cloud computing technologies, techniques, and integration approaches are widely being adopted, taught at the university level, and expected as key skills in the job market. The principles and practices of the software engineering and software architecture community can serve to help guide this emerging domain. The fundamental goal of the ICSE 2011 Software Engineering for Cloud Workshop is to bring together the diverse communities of cloud computing and of software engineering and architecture research with the hopes of sharing and disseminating key tribal knowledge between these rich areas. We expect as the workshop output a set of identified key software engineering challenges and important issues in the domain of cloud computing, specifically focused on how software engineering practice and research can play a role in shaping the next five years of research and practice for clouds. Furthermore, we expect to share "war stories", best practices and lessons learned between leaders in the software engineering and cloud computing communities.},
booktitle = {Proceedings of the 33rd International Conference on Software Engineering},
pages = {1196–1197},
numpages = {2},
keywords = {software engineering, secloud, cloud computing},
location = {Waikiki, Honolulu, HI, USA},
series = {ICSE '11}
}

@inproceedings{10.1145/3628034.3628060,
author = {Engelmann, Christian and Somnath, Suhas},
title = {Science Use Case Design Patterns for Autonomous Experiments},
year = {2024},
isbn = {9798400700408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628034.3628060},
doi = {10.1145/3628034.3628060},
abstract = {Connecting scientific instruments and robot-controlled laboratories with computing and data resources at the edge, the Cloud or the high-performance computing (HPC) center enables autonomous experiments, self-driving laboratories, smart manufacturing, and artificial intelligence (AI)-driven design, discovery and evaluation. The Self-driven Experiments for Science / Interconnected Science Ecosystem (INTERSECT) Open Architecture enables science breakthroughs using intelligent networked systems, instruments and facilities with a federated hardware/software architecture for the laboratory of the future. It relies on a novel approach, consisting of (1) science use case design patterns, (2) a system of systems architecture, and (3) a microservice architecture. This paper introduces the science use case design patterns of the INTERSECT Architecture. It describes the overall background, the involved terminology and concepts, and the pattern format and classification. It further offers an overview of the 12 defined patterns and 4 examples of patterns of 2 different pattern classes. It also provides insight into building solutions from these patterns. The target audience are computer, computational, instrument and domain science experts working in the field of autonomous experiments.},
booktitle = {Proceedings of the 28th European Conference on Pattern Languages of Programs},
articleno = {26},
numpages = {14},
keywords = {autonomous experiments, design patterns, federated ecosystem, smart laboratories, system architecture},
location = {Irsee, Germany},
series = {EuroPLoP '23}
}

@inproceedings{10.1145/3075564.3076259,
author = {Llewellynn, Tim and Fern\'{a}ndez-Carrobles, M. Milagro and Deniz, Oscar and Fricker, Samuel and Storkey, Amos and Pazos, Nuria and Velikic, Gordana and Leufgen, Kirsten and Dahyot, Rozenn and Koller, Sebastian and Goumas, Georgios and Leitner, Peter and Dasika, Ganesh and Wang, Lei and Tutschku, Kurt},
title = {BONSEYES: Platform for Open Development of Systems of Artificial Intelligence: Invited paper},
year = {2017},
isbn = {9781450344876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3075564.3076259},
doi = {10.1145/3075564.3076259},
abstract = {The Bonseyes EU H2020 collaborative project aims to develop a platform consisting of a Data Marketplace, a Deep Learning Toolbox, and Developer Reference Platforms for organizations wanting to adopt Artificial Intelligence. The project will be focused on using artificial intelligence in low power Internet of Things (IoT) devices ("edge computing"), embedded computing systems, and data center servers ("cloud computing"). It will bring about orders of magnitude improvements in efficiency, performance, reliability, security, and productivity in the design and programming of systems of artificial intelligence that incorporate Smart Cyber-Physical Systems (CPS). In addition, it will solve a causality problem for organizations who lack access to Data and Models. Its open software architecture will facilitate adoption of the whole concept on a wider scale. To evaluate the effectiveness, technical feasibility, and to quantify the real-world improvements in efficiency, security, performance, effort and cost of adding AI to products and services using the Bonseyes platform, four complementary demonstrators will be built. Bonseyes platform capabilities are aimed at being aligned with the European FI-PPP activities and take advantage of its flagship project FIWARE. This paper provides a description of the project motivation, goals and preliminary work.},
booktitle = {Proceedings of the Computing Frontiers Conference},
pages = {299–304},
numpages = {6},
keywords = {Smart Cyber-Physical Systems, Internet of things, Deep Learning, Data marketplace},
location = {Siena, Italy},
series = {CF'17}
}

@inproceedings{10.1145/3596454.3597184,
author = {Brie, Paul and Burny, Nicolas and Vanderdonckt, Jean},
title = {VisionAPI: An API for Offline and Online Segmentation and Identification of Hand-Sketched Graphical User Interfaces},
year = {2023},
isbn = {9798400702068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3596454.3597184},
doi = {10.1145/3596454.3597184},
abstract = {Segmentation and identification of a graphical user interface consist of detecting the location, dimensions, and arrangement of elements of the user interface, such as controls, labels, images, and icons, and recognizing them, respectively. While these problems have been already addressed for a graphical user interface stored in a file and processed offline, it has received less attention for online processing when the interface evolves and is expressed in different formats, such as a whiteboard drawing or a paper sketch. To overcome these limitations, we present VisionAPI, an application programming interface trained for segmenting and identifying elements of a hand-sketched graphical user interface both offline and online using computer vision. For this purpose, we rely on a software architecture based on Resnet101 to extract features and Faster R-CNN to build boundary boxes to obtain an 85\% recognition rate for 21 classes of elements found in graphical user interfaces: paragraph, dropdown list, checkbox, radio button, rating, toggle button, text area, date picker, stepper input, slider, video, label, table, list, header, button, image, linebreak, container, link, and text input.},
booktitle = {Companion Proceedings of the 2023 ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {59–67},
numpages = {9},
keywords = {Widget identification, User Interface segmentation, Gestural input, GUI layout, GUI element, Faster R-CNN, Edge detection, Convolutional Neural Network, Application Programming Interface},
location = {Swansea, United Kingdom},
series = {EICS '23 Companion}
}

@inproceedings{10.1109/ECASE.2019.00013,
author = {Yuan, Eric},
title = {Architecture interoperability and repeatability with microservices: an industry perspective},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ECASE.2019.00013},
doi = {10.1109/ECASE.2019.00013},
abstract = {Microservices, along with supporting technologies such as containers, have become a prevalent architecture approach for today's software systems, especially in enterprise environments. They represent the latest evolutionary step in the decades-old journey towards service- and component-based software architectures. Along with virtualization technologies, microservices have enabled the loose-coupling of both service interfaces (message passing) and service integration (form and fit). This paper attempts to explore the impact of microservices on software architecture interoperability and repeatability, based on our experiences in developing two microservice-based systems. Our central thesis is that, if we view software architecture as a set of principal design decisions, the microservices approach enable us to more elegantly separate these decisions from non-architectural, domain-specific ones, and thus make these decisions more interoperable, reusable, and repeatable across disparate problem domains. We therefore propose that a microservices based reference architecture (RA) and reference implementation (RI) be created for the community-wide infrastructure for software engineering and software architecture research, along with a set of detailed considerations.},
booktitle = {Proceedings of the 2nd International Workshop on Establishing a Community-Wide Infrastructure for Architecture-Based Software Engineering},
pages = {26–33},
numpages = {8},
keywords = {software architecture, microservice, cloud computing, DevOps},
location = {Montreal, Quebec, Canada},
series = {ECASE '19}
}

@inproceedings{10.1145/1370175.1370249,
author = {Avgeriou, Paris and Lago, Patricia and Kruchten, Philippe},
title = {Third international workshop on sharing and reusing architectural knowledge (SHARK 2008)},
year = {2008},
isbn = {9781605580791},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370175.1370249},
doi = {10.1145/1370175.1370249},
abstract = {The shift of the software architecture community towards architectural knowledge has brought along some promising research directions. In this workshop we discuss the issues that lead to the application of architectural knowledge in research and industrial practice; ongoing research and new ideas to advance the field. In its previous editions we examined the state of the art and practice, future challenges and trends. This third edition will discuss, among others, architectural knowledge as perceived by different research communities, including requirements engineering, service-oriented computing and international standardization.},
booktitle = {Companion of the 30th International Conference on Software Engineering},
pages = {1065–1066},
numpages = {2},
keywords = {architectural knowledge},
location = {Leipzig, Germany},
series = {ICSE Companion '08}
}

@inproceedings{10.1109/CCGRID.2010.20,
author = {Clarke, Roger},
title = {User Requirements for Cloud Computing Architecture},
year = {2010},
isbn = {9780769540399},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1109/CCGRID.2010.20},
doi = {10.1109/CCGRID.2010.20},
abstract = {To date, the literature on software architecture for cloud computing is focussed largely on the service provider, and inadequately reflects the fact that cloud computing is a form of client-server relationship. Architectures must also encompass the software and devices that users utilise in order to invoke functions in the cloud, and intermediary functions. A further problem with analyses to date is inadequate reflection of the risks that users are subject to when they use cloud services. This paper proposes a comprehensive model that reflects user needs, and identifies implications of the model for computer scientists working in the area.},
booktitle = {Proceedings of the 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing},
pages = {625–630},
numpages = {6},
keywords = {use-profile, security, risk management, risk, privacy, integrity assurance, compliance},
series = {CCGRID '10}
}

@inproceedings{10.1145/3377814.3381704,
author = {Li, Zheng},
title = {Using public and free platform-as-a-service (PaaS) based lightweight projects for software architecture education},
year = {2020},
isbn = {9781450371247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3377814.3381704},
doi = {10.1145/3377814.3381704},
abstract = {Background: Software architecture is a crucial while significantly challenging topic in the computer science curriculum. Although "learning by doing" is widely advocated to address this topic's abstract and fuzzy nature, educators are still facing various difficulties in practice, especially including students' vicious circle of inexperience and the mental model dilemma in experiential learning.Aims: To help break the aforementioned vicious circle and mental model dilemma, this work aims to investigate our educational strategy of using lightweight projects with public and free PaaS resources (1) to help students accumulate architectural experience from the early stage and (2) to facilitate strengthening students' fundamental architecture knowledge.Method: To collect more empirical evidence, we conducted action research on our educational strategy across three undergraduate-curriculum courses for two years. In particular, we employed the Technology Acceptance Model (TAM) to validate how well students received such an educational strategy.Results: The students involved in the relevant coursework generally gave positive feedback with respect to learning theoretical concepts and a set of architectural patterns. Meanwhile, we also observed diverse learning curves for utilizing PaaS resources.Conclusions: Although there still exist PaaS-related limits, our educational strategy can foster students' experiential learning and collaborative learning in fundamental architecture courses. We believe that there are also potentials to extend our work to broader and advanced courses of software architecture.},
booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Software Engineering Education and Training},
pages = {1–11},
numpages = {11},
keywords = {software architecture education, platform-as-a-service (PaaS), lightweight project, experiential learning, collaborative learning},
location = {Seoul, South Korea},
series = {ICSE-SEET '20}
}

@inproceedings{10.1145/3063386.3063768,
author = {Seitz, Andreas and Johanssen, Jan Ole and Bruegge, Bernd and Loftness, Vivian and Hartkopf, Volker and Sturm, Monika},
title = {A fog architecture for decentralized decision making in smart buildings},
year = {2017},
isbn = {9781450349895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3063386.3063768},
doi = {10.1145/3063386.3063768},
abstract = {The integration of humans into smart buildings raises challenges between meeting individual preferences and the generic rules set to optimize energy effectiveness of interest to organizations. Merging the individual preferences of multiple occupants that share thermal zones compounds the challenge. To address related challenges, we have developed FRODO (Fog Architecture for Decision Support in Organizations), an architecture designed to establish a location- aware environment for conflict negotiation and decision support that is based on fog computing. This paper describes the model transformation from a centralized software architecture towards a decentralized Cyber-Physical System (CPS) which encompasses sensors, actuators, and the occupants of smart buildings. The transformation is implemented through MIBO, a framework that allows occupants to control their environment. MIBO has been extended to introduce a fog layer for improved negotiation and conflict resolution. This enables additional benefits to be optimized, such as increased quality of service, reduced latency, and improved security and resilience. The fog layer, introduced with FRODO, allows occupants and organizations to express and discuss conflicts in decision-making, at their point of origin.},
booktitle = {Proceedings of the 2nd International Workshop on Science of Smart City Operations and Platforms Engineering},
pages = {34–39},
numpages = {6},
keywords = {software architecture, smart building fog computing, model transformation, human-in-the-loop, decision support, cyber-physical system},
location = {Pittsburgh, Pennsylvania},
series = {SCOPE '17}
}

@inproceedings{10.1145/3344948.3344959,
author = {Brandner, Klaus and Weinreich, Rainer},
title = {A recommender system for software architecture decision making},
year = {2019},
isbn = {9781450371421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3344948.3344959},
doi = {10.1145/3344948.3344959},
abstract = {Making the right design decisions for a software system is a difficult task. Inappropriate design decisions are often hard to reverse and can lead to high costs and a poor quality of the software product. To support architects in the decision-making process, we present a hybrid recommender system for software architecture decision making. The system provides recommendations for areas of system design and for design options within these areas. It uses two kinds of codified architectural knowledge for decision making: decision models for describing potential design options in a design space, and architectural profiles for documenting design decisions in different software systems. The developed recommender system is able to make recommendations early on in the decision-making process and provides more tailored recommendations the more software architecture knowledge is available. The system has been experimentally applied to microservice decision making.},
booktitle = {Proceedings of the 13th European Conference on Software Architecture - Volume 2},
pages = {22–25},
numpages = {4},
keywords = {software architecture, recommender system, microservices, design decisions},
location = {Paris, France},
series = {ECSA '19}
}

@proceedings{10.5555/3105503,
title = {SEAMS '17: Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
year = {2017},
isbn = {9781538615508},
publisher = {IEEE Press},
abstract = {The objective of the International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS) is to bring together researchers and practitioners from diverse areas to investigate, discuss, and examine the fundamental principles, state of the art, critical challenges, and applications of engineering self-adaptive and self-managing systems.Self-adaptation and self-management are key objectives in many modern and emerging software systems, including the industrial internet of things, cyber-physical systems, cloud computing, and mobile computing. These systems must be able to adapt themselves at run time to preserve and optimize their operation in the presence of uncertain changes in their operating environment, resource variability, new user needs, attacks, intrusions, and faults.Approaches to complement software-based systems with self-managing and self-adaptive capabilities are an important area of research and development, offering solutions that leverage advances in fields such as software architecture, fault-tolerant computing, programming languages, robotics, mixed-initiative systems, and run-time program analysis and verification. Additionally, research in this field is informed by related areas like biologically-inspired computing, artificial intelligence, machine learning, control systems, and agent-based systems. The SEAMS symposium focuses on applying software engineering to these approaches, including methods, techniques, and tools that can be used to support self-* properties like self-adaptation, self-management, self-healing, self-optimization, and self-configuration.},
location = {Buenos Aires, Argentina}
}

@inproceedings{10.1145/3123779.3123804,
author = {Haselb\"{o}ck, Stefan and Weinreich, Rainer and Buchgeher, Georg},
title = {Decision guidance models for microservices: service discovery and fault tolerance},
year = {2017},
isbn = {9781450348430},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123779.3123804},
doi = {10.1145/3123779.3123804},
abstract = {Introducing a microservice system is a challenging task and requires the exploration and documentation of several related areas of design. Exploration and documentation of software architecture design is supported by decision guidance models in software architecture. In this paper, we present such guidance models for several microservice system design areas, including service discovery and fault tolerance. The presented models have been created based on existing microservice literature and have been validated and refined in design workshops with business partners as part of a technical action research (TAR) study.},
booktitle = {Proceedings of the Fifth European Conference on the Engineering of Computer-Based Systems},
articleno = {4},
numpages = {10},
keywords = {technical action research (TAR), software architecture, microservices, design decisions, decision guidance models},
location = {Larnaca, Cyprus},
series = {ECBS '17}
}

@inproceedings{10.1145/2461121.2461140,
author = {Mulfari, Davide and Celesti, Antonio and Puliafito, Antonio and Villari, Massimo},
title = {How cloud computing can support on-demand assistive services},
year = {2013},
isbn = {9781450318440},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2461121.2461140},
doi = {10.1145/2461121.2461140},
abstract = {This paper investigates how Cloud computing can meet the demands of people with disabilities who occasionally use a shared computer. In this situation, customized assistive software can not be available to the user since security policies prevent from having enough privileges to change local system preferences. In order to address such issue, we discuss an open source software architecture combining a web-based remote desktop management solution with virtualization technology. This system allows disabled users to access a virtual desktop running personal assistive software solutions. Hence, the disabled user can interact with the same virtual environment from any networked physical computer via a standard web browser. In the end, we discuss the major technological issue for the achievement of such a scenario.},
booktitle = {Proceedings of the 10th International Cross-Disciplinary Conference on Web Accessibility},
articleno = {27},
numpages = {4},
keywords = {virtual machine, remote desktop, cloud computing, assistive technology, VNC, HTML5},
location = {Rio de Janeiro, Brazil},
series = {W4A '13}
}

@inproceedings{10.1145/3510455.3512777,
author = {Nadeem, Anas and Malik, Muhammad Zubair},
title = {A case for microservices orchestration using workflow engines},
year = {2022},
isbn = {9781450392242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510455.3512777},
doi = {10.1145/3510455.3512777},
abstract = {Microservices have become the de-facto software architecture for cloud-native applications. A contentious architectural decision in microservices is to compose them using choreography or orchestration. In choreography, every service works independently, whereas, in orchestration, there is a controller that coordinates service interactions. This paper makes a case for orchestration. The promise of microservices is that each microservice can be independently developed, deployed, tested, upgraded, and scaled. This makes them suitable for systems running on cloud infrastructures. However, microservice-based systems become complicated due to the complex interactions of various services, concurrent events, failing components, developers' lack of global view, and configurations of the environment. This makes maintaining and debugging such systems very challenging. We hypothesize that orchestrated services are easier to debug and to test this we ported the largest publicly available microservices' benchmark TrainTicket [24], which is implemented using choreography, to a fault-oblivious stateful workflow framework Temporal [19]. We report our experience in porting the code from traditional choreographed microservice architecture to one orchestrated by Temporal and present our initial findings of time to debug the 22 bugs present in the benchmark. Our findings suggest that an effort towards making a transition to orchestrated approach is worthwhile, making the ported code easier to debug.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {6–10},
numpages = {5},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-NIER '22}
}

@inproceedings{10.1145/1370888.1370891,
author = {Mikic-Rakic, Marija and Malek, Sam and Medvidovic, Nenad},
title = {Architecture-driven software mobility in support of QoS requirements},
year = {2008},
isbn = {9781605580227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1370888.1370891},
doi = {10.1145/1370888.1370891},
abstract = {Over the past decade researchers have shown that software architecture provides an appropriate level of granularity for assessing a system's Quality of Service (QoS) properties (e.g., latency). Similarly, many previous works have adopted an architecture-centric approach to reason about the runtime adaptation, including component mobility, of software systems. However, the relationship between software architecture, QoS, and mobility is not clearly understood. In this paper, we present a framework that takes an explicit software architecture perspective for assessing the system's QoS properties, and improving it through architectural mobility. We describe the implementation of the framework, as well as some of the remaining challenges that frame our ongoing work.},
booktitle = {Proceedings of the 1st International Workshop on Software Architectures and Mobility},
pages = {3–8},
numpages = {6},
keywords = {software architecture, qos, mobility},
location = {Leipzig, Germany},
series = {SAM '08}
}

@inproceedings{10.1145/3524304.3524306,
author = {Ding, Xiang and Zhang, Cheng},
title = {How Can We Cope with the Impact of Microservice Architecture Smells?},
year = {2022},
isbn = {9781450385770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524304.3524306},
doi = {10.1145/3524304.3524306},
abstract = {Context: Software Architecture Smells (AS) are potential software structure problems and always impact software quality negatively. And with the development of Microservice architecture, the Microservice Architecture Smells (MAS) have been attracting more and more attention. The software scholars and developers have discovered the influence of MAS and performed some researches on them. However, the definition and category of MAS are still ambiguous.Objects: This paper aims to clarify the specific MAS categories and their definitions, and then further explores the issues caused by MAS in the migration process from a monolithic system to Microservice.Method: We performed a comprehensive systematic literature review about MAS. Specifically, we explored 13 white and 10 grey literature in detail to get MAS information by using the quantitative research method. To explore the issues that influence the migration process from a monolithic system to Microservice, we used the meta-ethnography qualitative research method to extract relevant information and get six three-order translations.Results: This study defined 22 Microservice Architecture Smells and classified them into five categories, namely Design, Deployment, Monitor \&amp; Log, Communication and Team \&amp; Tool, based on their characteristics. Simultaneously, the issues that influence the migration process are proposed, including service cutting, databases, communication, team and techniques. Finally, we matched the MAS to the issues they caused in the migration process and recommended solutions to these issues.},
booktitle = {Proceedings of the 2022 11th International Conference on Software and Computer Applications},
pages = {8–14},
numpages = {7},
keywords = {smell impact, meta-ethnography, Systematic Literature Review, Microservice Architecture Smells},
location = {Melaka, Malaysia},
series = {ICSCA '22}
}

@inproceedings{10.1145/1559845.1559942,
author = {Weissman, Craig D. and Bobrowski, Steve},
title = {The design of the force.com multitenant internet application development platform},
year = {2009},
isbn = {9781605585512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1559845.1559942},
doi = {10.1145/1559845.1559942},
abstract = {Force.com is the preeminent on-demand application development platform in use today, supporting some 55,000+ organizations. Individual enterprises and commercial software-as-a-service (SaaS) vendors trust the platform to deliver robust, reliable, Internet-scale applications. To meet the extreme demands of its large user population, Force.com's foundation is a metadatadriven software architecture that enables multitenant applications.The focus of this paper is multitenancy, a fundamental design approach that can dramatically improve SaaS application management. This paper defines multitenancy, explains its benefits, and demonstrates why metadata-driven architectures are the premier choice for implementing multitenancy.},
booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data},
pages = {889–896},
numpages = {8},
keywords = {query optimization, object-relational mapping, multi-tenancy, flex schema, domain specific language},
location = {Providence, Rhode Island, USA},
series = {SIGMOD '09}
}

@inproceedings{10.1145/2342441.2342461,
author = {Raghavendra, Ramya and Lobo, Jorge and Lee, Kang-Won},
title = {Dynamic graph query primitives for SDN-based cloudnetwork management},
year = {2012},
isbn = {9781450314770},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2342441.2342461},
doi = {10.1145/2342441.2342461},
abstract = {The need to provide customers with the ability to configure the network in current cloud computing environments has motivated the Networking-as-a-Service (NaaS) systems designed for the cloud. Such systems can provide cloud customers access to virtual network functions, such as network-aware VM placement, real time network monitoring, diagnostics and management, all while supporting multiple device management protocols. These network management functionalities depend on a set of underlying graph primitives. In this paper, we present the design and implementation of the software architecture including a shared graph library that can support network management operations. Using the illustrative case of all pair shortest path algorithm, we demonstrate how scalable lightweight dynamic graph query mechanisms can be implemented to enable practical computation times, in presence of network dynamism.},
booktitle = {Proceedings of the First Workshop on Hot Topics in Software Defined Networks},
pages = {97–102},
numpages = {6},
keywords = {naas, graph},
location = {Helsinki, Finland},
series = {HotSDN '12}
}

@article{10.1145/2583687.2583699,
author = {Schwarz, Christian and Z\"{o}bel, Dieter and Wagner, Marco},
title = {Formal verification of service-oriented adaptive driver assistance systems},
year = {2013},
issue_date = {December 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {4},
url = {https://doi.org/10.1145/2583687.2583699},
doi = {10.1145/2583687.2583699},
abstract = {Many future Driver-Assistance-Systems (DAS) will use components not permanently mounted to the vehicle. Unlike state-of-the-art DAS with static configurations, the system and software architecture changes at runtime. To handle configuration changes, Service Oriented Architecture (SOA) and automatic orchestration is a promising approach. Whenever systems are set up automatically, they have to be validated. This paper presents an approach based on formal methods. Existing component models are annotated with Quality-of-Service parameters and transformed automatically to Hybrid Automata. These automata are then composed to an overall system model and model checking is used to check safety properties. The complete transformation-orchestration-validation process is executed without user interaction and thus can be performed at runtime.},
journal = {SIGBED Rev.},
month = dec,
pages = {49–52},
numpages = {4}
}

@inproceedings{10.1145/2095536.2095601,
author = {Maraoui, Raoudha and Mhamdi, Amel and Graiet, Mohamed and Kmimech, Mourad and Bhiri, Mohamed Tahar and Gaaloul, Walid and Cariou, Eric},
title = {Towards a transformation of composite web service with QoS extension into ACME\Armani},
year = {2011},
isbn = {9781450307840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2095536.2095601},
doi = {10.1145/2095536.2095601},
abstract = {In this paper, the work developed aims at contributing to the research related to the Quality of Service (QoS) for Web services. The aim of this research is twofold, first, it helps the designers and developers to provide better web services and second, and it helps ensure consistent software architecture as a reference model for many applications. To achieve this, we model, first, the meta-QoS model of the Web services. Then, we formalize the QoS of the Web services by referring to ARMANI. We also, handle the mediation of the composite Web services with the ACME using an automatic MDE approach and implementing a tool for this aim: Web services compositions are transformed onto ACME specifications.},
booktitle = {Proceedings of the 13th International Conference on Information Integration and Web-Based Applications and Services},
pages = {349–352},
numpages = {4},
keywords = {web services composition, transactional web services, formalization, automation, QoS, MDE, ACME/ARMANI},
location = {Ho Chi Minh City, Vietnam},
series = {iiWAS '11}
}

@proceedings{10.1145/1833335,
title = {SHARK '10: Proceedings of the 2010 ICSE Workshop on Sharing and Reusing Architectural Knowledge},
year = {2010},
isbn = {9781605589671},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SHARK workshop focuses on current and emerging methods, languages, notations, technologies and tools to create, extract, represent, share, use and re-use architectural knowledge. Architectural Knowledge (AK) is the integrated representation of the software architecture of a software-intensive system (or a family of systems), including the architectural design decisions, and the external context/environment. It is increasingly recognized as the means for architecture governance; it facilitates and supports collaboration and the transfer of expertise.Architectural knowledge has been established within the software architecture community as a self-contained research area in software architecture, and brought along some promising research directions. In this workshop we discuss the issues that lead to the application of architectural knowledge in research and industrial practice; ongoing research and new ideas to advance the field. In its four previous editions we examined: the state of the art and practice (2006), future challenges and trends (2007), architectural knowledge as perceived by different research communities, including requirements engineering, service-oriented computing and international standardization (2008), and the application, experimentation, specialization and use of architectural knowledge theory and approaches (2009).In this fifth SHARK edition we've asked the community to discuss and contribute on how to reorganize and codify the Body of Knowledge of the WICSA community (WICSA BOK). This is partially available through www.softwarearchitectureportal.org and www.wicsa.net, but it needs to be reorganized and unified. We see two broad objectives for this activity: (1) to codify the BOK in the way the potential users (i.e., the members of the architecture community) would like to see it; and (2) exploit Web 2.0 and social networking techniques to support AK sharing, and better reachability/usability (again) according to the actual needs of the community itself. SHARK contributions offer new ideas and R&amp;D results to shape the next generation of the WICSA BOK (www.softwarearchitectureportal.org).},
location = {Cape Town, South Africa}
}

@inproceedings{10.1145/2405679.2405687,
author = {Chen, Xing and Zhang, Ying and Zhang, Xiaodong and Wu, Yihan and Huang, Gang},
title = {A model-based framework for platform management in Cloud},
year = {2012},
isbn = {9781450316095},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2405679.2405687},
doi = {10.1145/2405679.2405687},
abstract = {System management becomes increasingly complex and brings high costs, especially with the advent of Cloud Computing. For controlling the management cost, in particular the manual management cost, many computer programs have been developed to take over manual management tasks or reduce their complexity and difficulty. These programs are usually hard-coded by languages like Java and C++, which bring enough capability and flexibility but also cause high programming effort and cost. This paper proposes an architecture based approach to developing the management programs in a simple but powerful enough manner. First of all, the manageability of a given platform is abstracted as a runtime model of the platform's software architecture, which can automatically and immediately propagate any observable runtime changes of the target platforms to the corresponding architecture models, and vice versa. Then the management programs will be developed using modeling languages, instead of those relatively "low-level" programming languages. Such architecture-level management programs bring many advantages related to the performance, interoperability, reusability and simplicity.},
booktitle = {Proceedings of the 11th International Workshop on Adaptive and Reflective Middleware},
articleno = {8},
numpages = {2},
keywords = {software architecture, models at runtime, cloud management},
location = {Montreal, Quebec, Canada},
series = {ARM '12}
}

@proceedings{10.1145/1988676,
title = {SHARK '11: Proceedings of the 6th International Workshop on SHAring and Reusing Architectural Knowledge},
year = {2011},
isbn = {9781450305969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The SHARK workshop focuses on current and emerging methods, languages, notations, technologies and tools to create, extract, represent, share, use and re-use architectural knowledge. Architectural Knowledge (AK) is the integrated representation of the software architecture of a software-intensive system (or a family of systems), including the architectural design decisions, and the external context/environment. It is increasingly recognized as the means for architecture governance; it facilitates and supports collaboration and the transfer of expertise.Architectural knowledge has been established within the software architecture community as a selfcontained research area, and brought along some promising research directions. In this workshop we discuss the issues that lead to the application of architectural knowledge in research and industrial practice; ongoing research and new ideas to advance the field. In its five previous editions we examined: the state of the art and practice (2006), future challenges and trends (2007), architectural knowledge as perceived by different research communities, including requirements engineering, service-oriented computing and international standardization (2008), the application, experimentation, specialization and use of architectural knowledge theory and approaches (2009), and the Body of Knowledge of the Software Architecture community (2010).In this sixth SHARK edition we plan to investigate the approaches for AK personalization, where knowledge is not codified through templates or annotations, but it is exchanged through the discussion between the different stakeholders. Therefore, the emphasis does not lie on resource-intensive documentation but on lightweight, just-in-time conversations facilitated by "knowledge yellow pages" (who knows what). The AK community has not explored AK personalization in depth, even though it has acknowledged its value as a viable approach. As SHARK is a discussion-intensive workshop, we will form small working groups that will discuss in detail the various aspects of AK personalization. The actual topics for discussion will be generated during the workshop with the following topics as a starting point: methods and tools for AK personalization, hybrid approaches (making the best of both personalization and codification), potential industrial practices or even full industrial case studies of AK personalization, and applying knowledge management theory of knowledge personalization.},
location = {Waikiki, Honolulu, HI, USA}
}

@inproceedings{10.1145/1862372.1862393,
author = {Bezemer, Cor-Paul and Zaidman, Andy},
title = {Multi-tenant SaaS applications: maintenance dream or nightmare?},
year = {2010},
isbn = {9781450301282},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1862372.1862393},
doi = {10.1145/1862372.1862393},
abstract = {Multi-tenancy is a relatively new software architecture principle in the realm of the Software as a Service (SaaS) business model. It allows to make full use of the economy of scale, as multiple customers - "tenants" - share the same application and database instance. All the while, the tenants enjoy a highly configurable application, making it appear that the application is deployed on a dedicated server. The major benefits of multi-tenancy are increased utilization of hardware resources and improved ease of maintenance, in particular on the deployment side. These benefits should result in lower overall application costs, making the technology attractive for service providers targeting small and medium enterprises (SME). However, as this paper advocates, a wrong architectural choice might entail that multi-tenancy becomes a maintenance nightmare.},
booktitle = {Proceedings of the Joint ERCIM Workshop on Software Evolution (EVOL) and International Workshop on Principles of Software Evolution (IWPSE)},
pages = {88–92},
numpages = {5},
location = {Antwerp, Belgium},
series = {IWPSE-EVOL '10}
}

@inproceedings{10.1145/2568088.2568098,
author = {Ewing, John M. and Menasc\'{e}, Daniel A.},
title = {A meta-controller method for improving run-time self-architecting in SOA systems},
year = {2014},
isbn = {9781450327336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2568088.2568098},
doi = {10.1145/2568088.2568098},
abstract = {This paper builds on SASSY, a system for automatically generating SOA software architectures that optimize a given utility function of multiple QoS metrics. In SASSY, SOA software systems are automatically re-architected when services fail or degrade. Optimizing both architecture and service provider selection presents a pair of nested NP-hard problems. Here we adapt hill-climbing, beam search, simulated annealing, and evolutionary programming to both architecture optimization and service provider selection. Each of these techniques has several parameters that influence their efficiency. We introduce in this paper a meta-controller that automates the run-time selection of heuristic search techniques and their parameters. We examine two different meta-controller implementations that each use online learning. The first implementation identifies the best heuristic search combination from various prepared combinations. The second implementation analyzes the current self-architecting problem (e.g. changes in performance metrics, service degradations/failures) and looks for similar, previously encountered re-architecting problems to find an effective heuristic search combination for the current problem. A large set of experiments demonstrates the effectiveness of the first meta-controller implementation and indicates opportunities for improving the second meta-controller implementation.},
booktitle = {Proceedings of the 5th ACM/SPEC International Conference on Performance Engineering},
pages = {173–184},
numpages = {12},
keywords = {soa, metaheuristics, meta-controlled qos optimization, heuristic search, combinatorial search techniques, autonomic computing, automated run-time software architecting},
location = {Dublin, Ireland},
series = {ICPE '14}
}

@inproceedings{10.1145/2675743.2776768,
author = {Lim, L\'{e}on and Conan, Denis},
title = {Concept of multiscoping for distributed event-based systems},
year = {2015},
isbn = {9781450332866},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2675743.2776768},
doi = {10.1145/2675743.2776768},
abstract = {Distributed Event-Based Systems (DEBS) provide a versatile solution for asynchronously exchanging data in a distributed system, loosely-coupled in space and time. In this work, the software architecture of a DEBS is composed of an overlay network of brokers that are responsible for routing data from producers to consumers. Important issues are the cost (in terms of exchanged messages) of the installation of routing filters (for advertisements and subscriptions) on the brokers, and the cost of routing notifications. In this work, we extend the usage of the concept of scope to propose the concept of multiscoping: the overlay of brokers is logically structured according to several dimensions (geographic location, network characteristics, client membership, etc.) with visibility filters installed at scope boundaries; these overlays are superposed; clients connect to brokers and express their scoping requirements on these dimensions; and distribution of notifications is controlled both by visibility and routing filters.},
booktitle = {Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems},
pages = {348–351},
numpages = {4},
keywords = {middleware, distributed event-based systems},
location = {Oslo, Norway},
series = {DEBS '15}
}
@inproceedings{10.1145/1816041.1816093,
author = {Giro-i-Nieto, Xavier and Ventura, Carles and Pont-Tuset, Jordi and Cortes, Silvia and Marques, Ferran},
title = {System architecture of a web service for Content-Based Image Retrieval},
year = {2010},
isbn = {9781450301176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1816041.1816093},
doi = {10.1145/1816041.1816093},
abstract = {This paper presents the system architecture of a Content-Based Image Retrieval system implemented as a web service. The proposed solution is composed of two parts, a client running a graphical user interface for query formulation and a server where the search engine explores an image repository. The separation of the user interface and the search engine follows a Service as a Software (SaaS) model, a type of cloud computing design where a single core system is online and available to authorized clients. The proposed architecture follows the REST software architecture and HTTP protocol for communications, two solutions that combined with metadata coded in RDF, make the proposed system ready for its integration in the semantic web. User queries are formulated by visual examples through a graphical interface and content is remotely accessed also through HTTP communication. Visual descriptors and similarity measures implemented in this work are mostly defined in the MPEG-7 standard, while textual metadata is coded according to the Dublin Core specifications.},
booktitle = {Proceedings of the ACM International Conference on Image and Video Retrieval},
pages = {358–365},
numpages = {8},
keywords = {Content-Based Image Uetrieval (CBIR), image similarity, information visualization, web service},
location = {Xi'an, China},
series = {CIVR '10}
}

@inproceedings{10.1109/MICRO56248.2022.00040,
author = {Khairy, Mahmoud and Alawneh, Ahmad and Barnes, Aaron and Rogers, Timothy G.},
title = {SIMR: Single Instruction Multiple Request Processing for Energy-Efficient Data Center Microservices},
year = {2023},
isbn = {9781665462723},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MICRO56248.2022.00040},
doi = {10.1109/MICRO56248.2022.00040},
abstract = {Contemporary data center servers process thousands of similar, independent requests per minute. In the interest of programmer productivity and ease of scaling, workloads in data centers have shifted from single monolithic processes toward a micro and nanoservice software architecture. As a result, single servers are now packed with many threads executing the same, relatively small task on different data.State-of-the-art data centers run these microservices on multi-core CPUs. However, the flexibility offered by traditional CPUs comes at an energy-efficiency cost. The Multiple Instruction Multiple Data execution model misses opportunities to aggregate the similarity in contemporary microservices. We observe that the Single Instruction Multiple Thread execution model, employed by GPUs, provides better thread scaling and has the potential to reduce frontend and memory system energy consumption. However, contemporary GPUs are ill-suited for the latency-sensitive microservice space.To exploit the similarity in contemporary microservices, while maintaining acceptable latency, we propose the Request Processing Unit (RPU). The RPU combines elements of out-of-order CPUs with lockstep thread aggregation mechanisms found in GPUs to execute microservices in a Single Instruction Multiple Request (SIMR) fashion. To complement the RPU, we also propose a SIMR-aware software stack that uses novel mechanisms to batch requests based on their predicted control-flow, split batches based on predicted latency divergence and map per-request memory allocations to maximize coalescing opportunities. Our resulting RPU system processes 5.7\texttimes{} more requests/joule than multi-core CPUs, while increasing single thread latency by only 1.44\texttimes{}.},
booktitle = {Proceedings of the 55th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {441–463},
numpages = {23},
keywords = {SIMT, data center, microservices, GPU},
location = {Chicago, Illinois, USA},
series = {MICRO '22}
}

@inproceedings{10.1145/3442381.3449905,
author = {Yu, Guangba and Chen, Pengfei and Chen, Hongyang and Guan, Zijie and Huang, Zicheng and Jing, Linxiao and Weng, Tianjun and Sun, Xinmeng and Li, Xiaoyun},
title = {MicroRank: End-to-End Latency Issue Localization with Extended Spectrum Analysis in Microservice Environments},
year = {2021},
isbn = {9781450383127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3442381.3449905},
doi = {10.1145/3442381.3449905},
abstract = {With the advantages of flexible scalability and fast delivery, microservice has become a popular software architecture in the modern IT industry. However, the explosion in the number of service instances and complex dependencies make the troubleshooting extremely challenging in microservice environments. To help understand and troubleshoot a microservice system, the end-to-end tracing technology has been widely applied to capture the execution path of each request. Nevertheless, the tracing data are not fully leveraged by cloud and application providers when conducting latency issue localization in the microservice environment. This paper proposes a novel system, named MicroRank, which analyzes clues provided by normal and abnormal traces to locate root causes of latency issues. Once a latency issue is detected by the Anomaly Detector in MicroRank, the cause localization procedure is triggered. MicroRank first distinguishs which traces are abnormal. Then, MicroRank’s PageRank Scorer module uses the abnormal and normal trace information as its input and differentials the importance of different traces to extended spectrum techniques . Finally, the spectrum techniques can calculate the ranking list based on the weighted spectrum information from PageRank Scorer to locate root causes more effectively. The experimental evaluations on a widely-used open-source system and a production system show that MicroRank achieves excellent results not only in one root cause situation but also in two issues that happen at the same time. Moreover, MicroRank makes 6\% to 22\% improvement in recall in localizing root causes compared to current state-of-the-art methods.},
booktitle = {Proceedings of the Web Conference 2021},
pages = {3087–3098},
numpages = {12},
keywords = {Microservice, PageRank, end-to-end tracing, root cause localization, spectrum analysis},
location = {Ljubljana, Slovenia},
series = {WWW '21}
}

@inproceedings{10.1145/2480362.2480441,
author = {Agrawal, Ashish and Prabhakar, T. V.},
title = {Hospitality of cloud platforms},
year = {2013},
isbn = {9781450316569},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2480362.2480441},
doi = {10.1145/2480362.2480441},
abstract = {Cloud computing facilitates instantaneous provisioning of resources through programmable interfaces, enabling software architects to design dynamic architectures of applications. Various kind of cloud services differ in terms of features exposed by them and quality of their services. Features exposed by cloud services not only impact the design process of an application but also the overall quality of that application. For designing and building quality softwares, a framework for investigating impact of underlying platform on an application's design process and quality is essential and is missing in the literature.In this work, we investigated the impact of cloud features and their quality on the application's design process. We defined the term "Hospitality" as the support provided by the underlying cloud platform towards building quality applications. A methodological framework based on software architecture body of knowledge, especially tactics, is provided in the paper. This framework can be used to investigate hospitality of cloud platforms and rank them using a "Hospitality Index". Utility of the framework in various architectural design decisions, e.g., selection of a cloud platform, selection of architectural components in designing applications, etc., is shown in the paper.},
booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
pages = {389–396},
numpages = {8},
location = {Coimbra, Portugal},
series = {SAC '13}
}

@inproceedings{10.5555/2693848.2693954,
author = {Suzumura, Toyotaro and Houngkaew, Charuwat and Kanezashi, Hiroki},
title = {Towards billion-scale social simulations},
year = {2014},
publisher = {IEEE Press},
abstract = {Many social simulations can be represented using mobile-agent-based model in which agents moving around on a given space such as evacuations, traffic flow and epidemics. Whole planet simulation with billions of agents at microscopic level helps mitigate the global crisis. It introduces new technical challenges such as processing and migrating many agents and load balancing among hundreds of machines. To overcome these challenges, well-designed software architecture of a simulator is essential. In this research, we proposed agent-based complex cellular automata architecture (ABCCA) and studied the performance and scalability of two cell-based processing models, through simple traffic flow simulation on multi-core distributed system. The experiments show that the computation speedup can be achieved by reducing granularity of tasks and processing only active spaces. We achieved running the traffic flow simulation with one billion of agents in almost real time on 1,536 CPU cores of total 128 machines of TSUBAME supercomputer.},
booktitle = {Proceedings of the 2014 Winter Simulation Conference},
pages = {781–792},
numpages = {12},
location = {Savannah, Georgia},
series = {WSC '14}
}

@inproceedings{10.1145/2304636.2304643,
author = {Vaupel, Robert},
title = {Operating systems development: driving forces, critical steps, decision processes},
year = {2012},
isbn = {9781450313490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2304636.2304643},
doi = {10.1145/2304636.2304643},
abstract = {Operating systems for server environments are seen as mature entities of Information Technology. The most visible Software Architecture enhancements are done on the middleware or even the application layers. Nevertheless operating systems lay out the architectural base for the higher software levels. Especially an operating system like z/OS for IBM mainframe servers highly interacts with middleware for assuring advanced quality of service attributes.This presentation will take a look at the development process of an operating system component of z/OS. We will take a look at the driving forces which lead to new developments or enhancements and the critical steps of the development process which ensure a high quality standard. At the end we will discuss an example how a decision for a functional enhancement is reached and which driving forces all need to be considered to come to the final conclusion.},
booktitle = {Proceedings of the 2012 ACM SIGSOFT Symposium on Industry Day},
pages = {15–18},
numpages = {4},
keywords = {operating systems, process},
location = {Bertinoro, Italy},
series = {Industry Day '12}
}

@inproceedings{10.1145/1294904.1294911,
author = {Medvidovic, Nenad and Malek, Sam},
title = {Software deployment architecture and quality-of-service in pervasive environments},
year = {2007},
isbn = {9781595937988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1294904.1294911},
doi = {10.1145/1294904.1294911},
abstract = {Over the past several years we have investigated two problems related to the domain of highly distributed, mobile, resource constrained, embedded, and pervasive environments: software deployment and quality of service (QoS). We have done so with the explicit focus on the role played by software architecture in deployment, and on its relationship to QoS. In the process, we have amassed a body of knowledge and experience, and assembled a suite of solutions for targeting different facets of the interplay among software architecture, deployment, and QoS. At the same time, the area we are addressing has proven to be multi-faceted and very complex, constantly presenting new challenges. In this paper we outline the contours of the problem of QoS in architecture-based deployment, our strategy for addressing it, and the challenges that remain. We view this as an important (and fruitful) area of research.},
booktitle = {International Workshop on Engineering of Software Services for Pervasive Environments: In Conjunction with the 6th ESEC/FSE Joint Meeting},
pages = {47–51},
numpages = {5},
location = {Dubrovnik, Croatia},
series = {ESSPE '07}
}

@inproceedings{10.1145/2749246.2749273,
author = {Ouyang, Jiannan and Kocoloski, Brian and Lange, John R. and Pedretti, Kevin},
title = {Achieving Performance Isolation with Lightweight Co-Kernels},
year = {2015},
isbn = {9781450335508},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2749246.2749273},
doi = {10.1145/2749246.2749273},
abstract = {Performance isolation is emerging as a requirement for High Performance Computing (HPC) applications, particularly as HPC architectures turn to in situ data processing and application composition techniques to increase system throughput. These approaches require the co-location of disparate workloads on the same compute node, each with different resource and runtime requirements. In this paper we claim that these workloads cannot be effectively managed by a single Operating System/Runtime (OS/R). Therefore, we present Pisces, a system software architecture that enables the co-existence of multiple independent and fully isolated OS/Rs, or enclaves, that can be customized to address the disparate requirements of next generation HPC workloads. Each enclave consists of a specialized lightweight OS co-kernel and runtime, which is capable of independently managing partitions of dynamically assigned hardware resources. Contrary to other co-kernel approaches, in this work we consider performance isolation to be a primary requirement and present a novel co-kernel architecture to achieve this goal. We further present a set of design requirements necessary to ensure performance isolation, including: (1) elimination of cross OS dependencies, (2) internalized management of I/O, (3) limiting cross enclave communication to explicit shared memory channels, and (4) using virtualization techniques to provide missing OS features. The implementation of the Pisces co-kernel architecture is based on the Kitten Lightweight Kernel and Palacios Virtual Machine Monitor, two system software architectures designed specifically for HPC systems. Finally we will show that lightweight isolated co-kernels can provide better performance for HPC applications, and that isolated virtual machines are even capable of outperforming native environments in the presence of competing workloads.},
booktitle = {Proceedings of the 24th International Symposium on High-Performance Parallel and Distributed Computing},
pages = {149–160},
numpages = {12},
keywords = {exascale, operating systems, virtualization},
location = {Portland, Oregon, USA},
series = {HPDC '15}
}

@inproceedings{10.1145/2676733.2676736,
author = {Lim, L\'{e}on and Conan, Denis},
title = {Distributed event-based system with multiscoping for multiscalability},
year = {2014},
isbn = {9781450332224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2676733.2676736},
doi = {10.1145/2676733.2676736},
abstract = {Distributed Event-Based System (DEBS) provides a versatile solution for asynchronously exchanging data in a distributed system, loosely-coupled in space and time. The software architecture of a DEBS is composed of an over-lay network of brokers that are responsible for routing data from producers to consumers. An important issue is the cost (in terms of exchanged messages) of the installation of advertisement or subscription filters on the brokers and the cost of routing notifications. The problem is exacerbated in large and heterogeneous systems involving clouds, cloudlets, desktops, laptops, mobile phones, and smart objects of the Internet of Things (IoT). In this paper, we associate the system concept of scale (of multiscale distributed systems) with the concept of scope (of DEBS) and we introduce DEBS with multiscoping. We also extend the requirements of distributed routing to deal with multiscoping. In the context of the IoT, we show in an illustrative example that the solution allows application designers and system administrators to tag advertisements and subscriptions for semantically delimiting scopes that are superposed.},
booktitle = {Proceedings of the 9th Workshop on Middleware for Next Generation Internet Computing},
articleno = {3},
numpages = {6},
keywords = {IoT, distributed event-based systems, middleware, multiscalability, scoping},
location = {Bordeaux, France},
series = {MW4NG '14}
}

@inproceedings{10.1145/1858263.1858265,
author = {Noorshams, Qais and Martens, Anne and Reussner, Ralf},
title = {Using quality of service bounds for effective multi-objective software architecture optimization},
year = {2010},
isbn = {9781450302395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1858263.1858265},
doi = {10.1145/1858263.1858265},
abstract = {Quantitative prediction of non-functional properties, such as performance, reliability, and cost, of software architectures supports systematic software engineering. Even though there usually is a rough idea on bounds for quality of service, the exact required values may be unclear and subject to tradeoffs. Designing architectures that exhibit such good tradeoff between multiple quality attributes is hard. Even with a given functional design, many degrees of freedom in the software architecture (e.g. component deployment or server configuration) span a large design space. Automated approaches search the design space with multi-objective meta-heuristics such as evolutionary algorithms. However, as quality prediction for a single architecture is computationally expensive, these approaches are time consuming. In this work, we enhance an automated improvement approach to take into account bounds for quality of service in order to focus the search on interesting regions of the objective space, while still allowing trade-offs after the search. To validate our approach, we applied it to an architecture model of a component-based business information system. We compared the search to an unbounded search by running the optimization 8 times, each investigating around 800 candidates. The approach decreases the time needed to find good solutions in the interesting regions of the objective space by more than 35\% on average.},
booktitle = {Proceedings of the 2nd International Workshop on the Quality of Service-Oriented Software Systems},
articleno = {1},
numpages = {6},
keywords = {optimization, performance, quality attribute prediction, reliability, software architecture},
location = {Oslo, Norway},
series = {QUASOSS '10}
}

@inproceedings{10.5555/2008503.2008553,
author = {Koziolek, Anne and Noorshams, Qais and Reussner, Ralf},
title = {Focussing multi-objective software architecture optimization using quality of service bounds},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Quantitative prediction of non-functional properties, such as performance, reliability, and costs, of software architectures supports systematic software engineering. Even though there usually is a rough idea on bounds for quality of service, the exact required values may be unclear and subject to trade-offs. Designing architectures that exhibit such good trade-off between multiple quality attributes is hard. Even with a given functional design, many degrees of freedom in the software architecture (e.g. component deployment or server configuration) span a large design space. Automated approaches search the design space with multi-objective metaheuristics such as evolutionary algorithms. However, as quality prediction for a single architecture is computationally expensive, these approaches are time consuming. In this work, we enhance an automated improvement approach to take into account bounds for quality of service in order to focus the search on interesting regions of the objective space, while still allowing trade-offs after the search. We compare two different constraint handling techniques to consider the bounds. To validate our approach, we applied both techniques to an architecture model of a component-based business information system. We compared both techniques to an unbounded search in 4 scenarios. Every scenario was examined with 10 optimization runs, each investigating around 1600 architectural candidates. The results indicate that the integration of quality of service bounds during the optimization process can improve the quality of the solutions found, however, the effect depends on the scenario, i.e. the problem and the quality requirements. The best results were achieved for costs requirements: The approach was able to decrease the time needed to find good solutions in the interesting regions of the objective space by 25\% on average.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {384–399},
numpages = {16},
keywords = {optimization, performance, quality attribute prediction, reliability, software architecture},
location = {Oslo, Norway},
series = {MODELS'10}
}

@article{10.1145/1721695.1721704,
author = {Lin, Chang Hong and Wolf, Marilyn and Koutsoukos, Xenefon and Neema, Sandeep and Sztipanovits, Janos},
title = {System and software architectures of distributed smart cameras},
year = {2010},
issue_date = {March 2010},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {4},
issn = {1539-9087},
url = {https://doi.org/10.1145/1721695.1721704},
doi = {10.1145/1721695.1721704},
abstract = {In this article, we describe a distributed, peer-to-peer gesture recognition system along with a software architecture modeling technique and authority control protocol for ubiquitous cameras. This system performs gesture recognition in real time by combining imagery from multiple cameras without using a central server. We propose a system architecture that uses a network of inexpensive cameras to perform in-network video processing. A methodology for transforming well-designed single-node algorithm to distributed system is also proposed. Applications for ubiquitous cameras can be modeled as the composition of a finite-state machine of the system, functional services, and middleware. A service-oriented software architecture is proposed to dynamically reconfigure services when system state changes. By exchanging data and control messages between neighboring sensors, each node can maintain broader view of the environment with integrated video-processing results. Our prototype system is built on Windows machines, and uses standard video cameras as sensors and local network as a communication channel.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = apr,
articleno = {38},
numpages = {30},
keywords = {Distributed cameras, smart camera, software architecture}
}

@article{10.1145/2670967.2670969,
author = {Oliveira, Daniela and Wetzel, Nicholas and Bucci, Max and Navarro, Jesus and Sullivan, Dean and Jin, Yier},
title = {Hardware-software collaboration for secure coexistence with kernel extensions},
year = {2014},
issue_date = {September 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {3},
issn = {1559-6915},
url = {https://doi.org/10.1145/2670967.2670969},
doi = {10.1145/2670967.2670969},
abstract = {Our society is dependent upon computer systems that are the target of a never-ending siege against their resources. One powerful avenue for exploitation is the operating system kernel, which has complete control of a computer system's resources. The current methodology for kernel design, which involves loadable extensions from third parties, facilitates compromises. Most of these extensions are benign, but in general they pose a threat to system trustworthiness: they run as part of the kernel and some of them can be vulnerable or malicious. This situation is paradoxical from a security point of view: modern OSes depend, and must co-exist, with untrustworthy but needed extensions. Similarly, the immune system is continuously at war against various types of invaders and, through evolution, has developed highly successful defense mechanisms. Collaboration is one of these mechanisms, where many players throughout the body effectively communicate to share attack intelligence. Another mechanism is foreign body co-existence with its microbiota. Remarkably, these properties are not leveraged in kernel defense approaches. Security approaches at the OS and virtual machine layers do not cooperate with each other or with the hardware. This paper advocates a new paradigm for OS defense based on close collaboration between an OS and the hardware infrastructure, and describes a hardware-software architecture realizing this vision. It also discusses the architecture design at the OS and hardware levels, including experimental results from an emulator-based prototype, and aspects of an ongoing hardware implementation. The emulator-based proof-of-concept prototype, Ianus, uses Linux as the OS and the Bochs x86 emulator as the architecture layer. It successfully minimized kernel extensions interactions with the original kernel. Its security was evaluated with real rootkits and benign extensions. Ianus' performance was analyzed with system and CPU benchmarks and it caused a small overhead to the system (approximately 12\%).},
journal = {SIGAPP Appl. Comput. Rev.},
month = sep,
pages = {22–35},
numpages = {14},
keywords = {HW-SW collaboration, OS defense, immune system, kernel extensions}
}

@article{10.1145/2492385.2492394,
author = {Aslam, Muhammad Sohaib and Rea, Susan and Pesch, Dirk},
title = {Provisioning within a WSAN cloud concept},
year = {2013},
issue_date = {February 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1145/2492385.2492394},
doi = {10.1145/2492385.2492394},
abstract = {Traditionally, Wireless Sensor and Actuator Networks or (WSANs) have been used as a standalone technology for a specific application purpose such as heating control. The current growth in embedded ICT infrastructure is leading to the deployment of a wide range of embedded systems in our environment, which motivates System of Systems [5] architectures and ultimately, with deployment of IP technologies into this space, the Internet of Things [10] paradigm. However, to simplify system operation and maintenance as well as to reduce costs, WSANs must become an infrastructure that is capable of providing services to multiple end users concurrently rather than requiring a new infrastructure for a new purpose. Here, we present the concept of a WSAN infrastructure as a WSAN Cloud, which provides services to multiple application and data collection systems following the cloud computing paradigm. Each instance of the WSAN cloud (i.e. a specific set of services configured by a particular end user/system) utilises the WSAN infrastructure as if it was a unique network provisioned for specific requirements. A realisation of the WSAN Cloud in the form of Network as a Service or NaaS requires a WSAN to support a service orientated software architecture allowing other systems to provision the WSAN infrastructure for their specific needs and allowing multiple systems to use the WSAN uniquely and concurrently. The WSAN-Service Orchestration Architecture "WSAN-SOrA" presented here, is a novel approach to service provisioning of embedded networked systems and enables WSANs to act as cloud ready infrastructures that facilitate on-demand provisioning for potentially multiple individual backend systems.},
journal = {SIGBED Rev.},
month = feb,
pages = {48–53},
numpages = {6}
}

@inproceedings{10.1145/3053600.3053653,
author = {Heinrich, Robert and van Hoorn, Andr\'{e} and Knoche, Holger and Li, Fei and Lwakatare, Lucy Ellen and Pahl, Claus and Schulte, Stefan and Wettinger, Johannes},
title = {Performance Engineering for Microservices: Research Challenges and Directions},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053653},
doi = {10.1145/3053600.3053653},
abstract = {Microservices complement approaches like DevOps and continuous delivery in terms of software architecture. Along with this architectural style, several important deployment technologies, such as container-based virtualization and container orchestration solutions, have emerged. These technologies allow to efficiently exploit cloud platforms, providing a high degree of scalability, availability, and portability for microservices.Despite the obvious importance of a sufficient level of performance, there is still a lack of performance engineering approaches explicitly taking into account the particularities of microservices. In this paper, we argue why new solutions to performance engineering for microservices are needed. Furthermore, we identify open issues and outline possible research directions with regard to performance-aware testing, monitoring, and modeling of microservices.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {223–226},
numpages = {4},
keywords = {continuous delivery, microservices, software performance engineering},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/3338906.3341176,
author = {Gamez-Diaz, Antonio and Fernandez, Pablo and Ruiz-Cort\'{e}s, Antonio},
title = {Governify for APIs: SLA-driven ecosystem for API governance},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3341176},
doi = {10.1145/3338906.3341176},
abstract = {As software architecture design is evolving to a microservice paradigm, RESTful APIs are being established as the preferred choice to build applications. In such a scenario, there is a shift towards a growing market of APIs where providers offer different service levels with tailored limitations typically based on the cost. In such a context, while there are well-established standards to describe the functional elements of APIs (such as the OpenAPI Specification), having a standard model for Service Level Agreements (SLAs) for APIs may boost an open ecosystem of tools that would represent an improvement for the industry by automating certain tasks during the development. In this paper, we introduce Governify for APIs, an ecosystem of tools aimed to support the user during the SLA-Driven RESTful APIs’ development process. Namely, an SLA Editor, an SLA Engine and an SLA Instrumentation Library. We also present a fully operational SLA-Driven API Gateway built on the top of our ecosystem of tools. To evaluate our proposal, we used three sources for gathering validation feedback: industry, teaching and research. Website: <a>links.governify.io/link/GovernifyForAPIs</a> Video: <a>links.governify.io/link/GovernifyForAPIsVideo</a>},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1120–1123},
numpages = {4},
keywords = {API Gateways, OpenAPI Specification, RESTful APIs, SLA, SLA-driven APIs},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/3357141.3357599,
author = {Costa, Ana Claudia L. A. I. and Colanzi, Thelma E. and Marcolino, Anderson S. and Barbosa, Ellen F.},
title = {Microservice-oriented Product Line Architecture Design: An Exploratory Study},
year = {2019},
isbn = {9781450376372},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357141.3357599},
doi = {10.1145/3357141.3357599},
abstract = {Microservice has been successfully employed in software industry [1, 11], as they provide modularization and easy management of small and autonomous services, high availability, scalability and short time-to-market. A recent study on microservices shows that most studies generate specific solutions, which emphasize the need for fundamental research, proposals of reusable practices and works that focus on providing information to ease communication between architects and stakeholders [11] -- software architecture can be a powerful tool for this regard. The definition and documentation of the software product line architecture (PLA) is an important activity, especially for inception and extraction of microservice-oriented PLA, because they involve decisions about how to design customizable microservices, how to arrange the communication between microsservices and APIs, etc. In this work, it is proposed a metamodel for the specification of microsserve-oriented PLA design in order to assist the developer in carrying out such an activity. The proposed metamodel was validated in an exploratory study, in which a new PLA was designed through the instantiation of the proposed metamodel and a product was configured from the designed PLA. Both the metamodel and its instantiation were evaluated in a survey involving software developers. The results indicate that the metamodel addresses the structural needs of microservice-oriented architectures. The main contributions of this work are (i) to assist the software product line developers in the specification and documentation of microservice-oriented PLA design and (ii) the lessons about the industrial practice learned from the surveys that are useful to enhance the proposed metamodel.},
booktitle = {Proceedings of the XIII Brazilian Symposium on Software Components, Architectures, and Reuse},
pages = {113–122},
numpages = {10},
location = {Salvador, Brazil},
series = {SBCARS '19}
}

@inproceedings{10.1145/3126858.3126880,
author = {Dilli, Renato and Filho, Huberto Kaiser and Pernas, Ana Marilza and Yamin, Adenauer},
title = {EXEHDA-RR: Machine Learning and MCDA with Semantic Web in IoT Resources Classification},
year = {2017},
isbn = {9781450350969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3126858.3126880},
doi = {10.1145/3126858.3126880},
abstract = {Currently, a lot of resources are connected to the Internet, many simultaneously requesting and providing services. The adequate selection of resources that best meet the demands of users with a broad range of options has been a relevant and current research challenge. Based on the non-functional parameters of QoS play a significant role in the ranking of these resources according to the services they offer. This paper aims to aggregate machine learning in the pre-classification of EXEHDA middleware resources, to reduce the computational cost generated by MCDA algorithms. We presented the proposed software architecture (EXEHDA-RR), and the obtained results with the integration of machine learning in the classification process are promissing, and indicate to the research continuation.},
booktitle = {Proceedings of the 23rd Brazillian Symposium on Multimedia and the Web},
pages = {293–300},
numpages = {8},
keywords = {internet of things, machine learning, mcda, resource ranking},
location = {Gramado, RS, Brazil},
series = {WebMedia '17}
}

@inproceedings{10.1145/1071021.1071028,
author = {Caporuscio, Mauro and Marco, Antinisca Di and Inverardi, Paola},
title = {Run-time performance management of the Siena publish/subscribe middleware},
year = {2005},
isbn = {1595930876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1071021.1071028},
doi = {10.1145/1071021.1071028},
abstract = {Recently, growing attention is focused on run-time management of Quality of Service (QoS) of complex software systems. In this context, self-adaptation of applications, based on runtime monitoring and dynamic reconfiguration, is considered a useful technique to manage/negotiate QoS. Several defined approaches to dynamic performance management propose the use of on-line model-based evaluation of the managed application in order to choose the new application configuration for improving the QoS. In a previous work we defined a methodology to manage performance of soft-ware system at run-time based on model-based performance evaluation. To avoid unnecessary details the performance model represents the managed application at the Software Architecture level. In this work we apply and implement this approach to dynamic manage the performance of the SIENA publish/subscribe event notification service.},
booktitle = {Proceedings of the 5th International Workshop on Software and Performance},
pages = {65–74},
numpages = {10},
keywords = {dynamic reconfiguration, performance analysis, performance model reconfiguration},
location = {Palma, Illes Balears, Spain},
series = {WOSP '05}
}

@inproceedings{10.1145/2346536.2346538,
author = {Elakehal, Emad Eldeen and Padget, Julian},
title = {Market intelligence and price adaptation},
year = {2012},
isbn = {9781450311977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2346536.2346538},
doi = {10.1145/2346536.2346538},
abstract = {In the context of e-commerce, it is critical for a retailing company to be able to assess the market and respond quickly to changes in competition and/or service levels and availability of its products. If the company operates globally, and the geographical constraints on the supplier are different from those on the consumer, it is even more crucial to assess each market with respect to its characteristics and dynamically price every individual product accordingly. In this paper we report on an agent-based distributed system that was developed to support the retailing operations of one of the largest online book sellers in the UK, which has millions of books on offer and operates internationally in a number of market places. The system supports the collection of market data, processing of this data, and applying dynamically one of set of predefined pricing patterns. We describe the principles on which the price adaptation is based, the (long-running and proven successful) distributed scalable software architecture that supports it, illustrate how the mechanism copes with some typical situations system that arise and highlight some of the lessons learned from the development experience.},
booktitle = {Proceedings of the 14th Annual International Conference on Electronic Commerce},
pages = {9–16},
numpages = {8},
keywords = {e-commerce, marketplaces, multiagent systems, real-time differential pricing},
location = {Singapore, Singapore},
series = {ICEC '12}
}

@inproceedings{10.1145/3127479.3132690,
author = {Tsai, Chin and Moh, Melody},
title = {Abstract: cache management and load balancing for 5G cloud radio access networks},
year = {2017},
isbn = {9781450350280},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3127479.3132690},
doi = {10.1145/3127479.3132690},
abstract = {Cloud Radio Access Networks (CRAN) has been proposed for 5G networks for better flexibility, scalability, and performance. CRAN aims to apply cloud-like architecture on RAN. This paper focuses on cache management and load balance in the software architecture of CRAN, intends to provide fault mitigation and carrier-grade real-time services. First, a new cache management algorithm based on event frequency and QoS level of User Equipment (UE) is proposed, utilizing Exponential Decay scoring function and Analytic Hierarchy Process. Next, load balance (LB) function is added, and five LB algorithms are evaluated. The performance evaluation is based on real-life UE event characteristics and RAN system values provided by Nokia Research. Results show the cache hit rate, delay and network traffic; as well as the queue-length analysis of LB algorithms.},
booktitle = {Proceedings of the 2017 Symposium on Cloud Computing},
pages = {630},
numpages = {1},
keywords = {5G networks, cache management, load balance},
location = {Santa Clara, California},
series = {SoCC '17}
}

@inproceedings{10.1145/1168054.1168064,
author = {Cabri, Giacomo and Leonardi, Letizia and Quitadamo, Raffaele},
title = {Enabling Java mobile computing on the IBM Jikes research virtual machine},
year = {2006},
isbn = {3939352055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1168054.1168064},
doi = {10.1145/1168054.1168064},
abstract = {Today's complex applications must face the distribution of data and code among different network nodes. Java is a wide-spread language that allows developers to build complex software, even distributed, but it cannot handle the migration of computations (i.e. threads), due to intrinsic limitations of many traditional JVMs. After analyzing the approaches in literature, this paper presents our research work on the IBM Jikes Research Virtual Machine: exploiting some of its innovative VM techniques, we implemented an extension of its scheduler that allows applications to easily capture the state of a running thread and makes it possible to restore it elsewhere (i.e. on a different hardware or software architecture, but still with a version of JikesRVM installed). Our thread serialization mechanism provides support for both proactive and reactive migration of single- and multi-threaded Java applications. With respect to previous approaches, we implemented the mobility framework without recompiling a previous JVM source code, but simply extending its functionalities with a full Java package.},
booktitle = {Proceedings of the 4th International Symposium on Principles and Practice of Programming in Java},
pages = {62–71},
numpages = {10},
keywords = {Java virtual machine, code mobility, distributed applications, thread persistence},
location = {Mannheim, Germany},
series = {PPPJ '06}
}

@inproceedings{10.1145/1666091.1666093,
author = {Harper, Simon},
title = {NeoVictorian computing, with a twist},
year = {2008},
isbn = {9781605581705},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1666091.1666093},
doi = {10.1145/1666091.1666093},
abstract = {Experience in World Wide Web (Web) accessibility has taught us: to think about small bespoke solutions; to tailor interaction and requirements to the user and job at hand; to value high data interoperability; to realise that large enterprise systems, become unmanageable and unable to change at the speed required by both users and technology; and finally, to value heterogeneity. Indeed, with the advent of Workflows, Remote Procedure Calls (RPCs), Representational state transfer (RESTful) services, and Cloud Computing we can also see these viewpoints becoming more common in mainstream thought. Here, we use Bernstein's concept of 'NeoVictorian Computing' as a counterfoil to Andriole's new viewpoint of 21st century software development. We extrapolate from the Web development model into corporate and enterprise systems and propose an architecture of client based heterogeneous applications each tailored to a specific user, and their job, with highly interoperable data, controlled by workflows that are transferred with the data itself. We discount the new client--computing fad, as this really means centrally controlled, sometimes unavailable, old style enterprise systems. We suggest that by moving toward user centred agile systems we follow the conceptual, if not the technological, underpinnings of the Web. In this case we realise that Web developers are in a privileged position to shape and push forward this new kind of software architecture and the 'craft' based approaches which will drive it.},
booktitle = {Proceedings of the 14th Brazilian Symposium on Multimedia and the Web},
pages = {1–3},
numpages = {3},
keywords = {accessibility, agile systems, cloud computing, human factors, world wide web},
location = {Vila Velha, Brazil},
series = {WebMedia '08}
}

@inproceedings{10.1145/1411273.1411280,
author = {Sch\"{u}tt, Thorsten and Schintke, Florian and Reinefeld, Alexander},
title = {Scalaris: reliable transactional p2p key/value store},
year = {2008},
isbn = {9781605580654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1411273.1411280},
doi = {10.1145/1411273.1411280},
abstract = {We present Scalaris, an Erlang implementation of a distributed key/value store. It uses, on top of a structured overlay network, replication for data availability and majority based distributed transactions for data consistency. In combination, this implements the ACID properties on a scalable structured overlay.By directly mapping the keys to the overlay without hashing, arbitrary key-ranges can be assigned to nodes, thereby allowing a better load-balancing than would be possible with traditional DHTs. Consequently, Scalaris can be tuned for fast data access by taking, e.g. the nodes' geographic location or the regional popularity of certain keys into account. This improves Scalaris' lookup speed in datacenter or cloud computing environments.Scalaris is implemented in Erlang. We describe the Erlang software architecture, including the transactional Java interface to access Scalaris.Additionally, we present a generic design pattern to implement a responsive server in Erlang that serializes update operations on a common state, while concurrently performing fast asynchronous read requests on the same state.As a proof-of-concept we implemented a simplified Wikipedia frontend and attached it to the Scalaris data store backend. Wikipedia is a challenging application. It requires - besides thousands of concurrent read requests per seconds - serialized, consistent write operations. For Wikipedia's category and backlink pages, keys must be consistently changed within transactions. We discuss how these features are implemented in Scalaris and show its performance.},
booktitle = {Proceedings of the 7th ACM SIGPLAN Workshop on ERLANG},
pages = {41–48},
numpages = {8},
keywords = {key/value store, peer-to-peer, transactions, wikipedia},
location = {Victoria, BC, Canada},
series = {ERLANG '08}
}

@inproceedings{10.1145/3338906.3340445,
author = {Gamez-Diaz, Antonio and Fernandez, Pablo and Ruiz-Cort\'{e}s, Antonio and Molina, Pedro J. and Kolekar, Nikhil and Bhogill, Prithpal and Mohaan, Madhurranjan and M\'{e}ndez, Francisco},
title = {The role of limitations and SLAs in the API industry},
year = {2019},
isbn = {9781450355728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338906.3340445},
doi = {10.1145/3338906.3340445},
abstract = {As software architecture design is evolving to a microservice paradigm, RESTful APIs are being established as the preferred choice to build applications. In such a scenario, there is a shift towards a growing market of APIs where providers offer different service levels with tailored limitations typically based on the cost.  In this context, while there are well established standards to describe the functional elements of APIs (such as the OpenAPI Specification), having a standard model for Service Level Agreements (SLAs) for APIs may boost an open ecosystem of tools that would represent an improvement for the industry by automating certain tasks during the development such as: SLA-aware scaffolding, SLA-aware testing, or SLA-aware requesters.  Unfortunately, despite there have been several proposals to describe SLAs for software in general and web services in particular during the past decades, there is an actual lack of a widely used standard due to the complex landscape of concepts surrounding the notion of SLAs and the multiple perspectives that can be addressed.  In this paper, we aim to analyze the landscape for SLAs for APIs in two different directions: i) Clarifying the SLA-driven API development lifecycle: its activities and participants; 2) Developing a catalog of relevant concepts and an ulterior prioritization based on different perspectives from both Industry and Academia.  As a main result, we present a scored list of concepts that paves the way to establish a concrete road-map for a standard industry-aligned specification to describe SLAs in APIs.},
booktitle = {Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1006–1014},
numpages = {9},
keywords = {API Gateways, OpenAPI Specification, RESTful APIs, SLA, SLA-driven APIs},
location = {Tallinn, Estonia},
series = {ESEC/FSE 2019}
}

@inproceedings{10.1145/1272980.1272983,
author = {Novelli, Giovanni and Pappalardo, Giuseppe and Santoro, Corrado and Tramontana, Emiliano},
title = {A grid-based infrastructure to support multimedia content distribution},
year = {2007},
isbn = {9781595937186},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1272980.1272983},
doi = {10.1145/1272980.1272983},
abstract = {This paper proposes a software architecture able to realise a Content Distribution Network (CDN), for multimedia data, by means of a Grid computing environment. The key aspect of the proposed approach is exploiting the computational power of a Grid not only to store replicas of the same multimedia content, but also to perform on-the-fly transcoding, when the requesting client is using a player that cannot handle the original file format.The proposed software infrastructure, which exploits Globus Grid services, is able on one hand to identify the storage element, holding the replica, which is the nearest to the client (if such a replica exists); and on the other hand, when the requested file is encoded with a scheme that the player cannot support, the infrastructure selects the computing element which is "best suited" - i.e. has enough computational power - to perform on-the-fly transcoding, thus providing data to the user with the requested format. This selection is based on proper metrics that aim at minimising latencies in order to increase the quality-of-service for the user.},
booktitle = {Proceedings of the Second Workshop on Use of P2P, GRID and Agents for the Development of Content Networks},
pages = {57–64},
numpages = {8},
keywords = {content distribution networks, grids, multimedia streaming and transcoding, quality-of-service},
location = {Monterey, California, USA},
series = {UPGRADE '07}
}

@inproceedings{10.1145/3291940.3291969,
author = {Chen, Zhongheng and Ji, Fei and Yu, Hua and Guan, Quansheng and Chen, Fangjiong},
title = {Protocol emulation platform based on microservice architecture for underwater acoustic networks},
year = {2018},
isbn = {9781450361934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3291940.3291969},
doi = {10.1145/3291940.3291969},
abstract = {As use of underwater applications increases, simulation studies on underwater acoustic networks (UAN) have also increasingly appeared. At present, the commonly used network simulation platforms are NS2 and NS3, or are extended from them. These simualation platforms require users to have rich experience in C++ programming because they integrate many complicated APIs, and the configuration process is cumbersome. Without further optimizing these existing emulation platforms from the software architecture, it is often impossible for the protocol researchers to completely focus on the logic implementation of the protocol without paying attention to the compilation and loading operation of the simulation software itself. In this paper, an UAN protocol emulation platform based on microservice architecture (MSA) is proposed. The microservices are independently developed and deployed to overcome the shortcomings of the traditional monolithic architecture for the development of software system. Using MSA, the protocols and functional modules are fully componentized, which is convenient for users to customize the UAN protocol stack, network behavior, and underlying physical devices. The proposed emulation platform can be deployed as a cloud-based server and provides users with services, such as simulation on demand, emulation in real time, monitoring and statistical analyzing, and other customizable extension functions. This operation mode is called emulation as a service (EaaS). A preliminary test has verified the feasibility of the whole framework and demonstrated that our implementation fulfills the main functions of this emulation platform.},
booktitle = {Proceedings of the 13th International Conference on Underwater Networks \& Systems},
articleno = {12},
numpages = {8},
keywords = {message queue, microservice architecture, protocol emulation platform, underwater acoustic networks},
location = {Shenzhen, China},
series = {WUWNet '18}
}

@inproceedings{10.1007/11424529_1,
author = {Liu, Yan and Gorton, Ian},
title = {Performance prediction of J2EE applications using messaging protocols},
year = {2005},
isbn = {3540258779},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
url = {https://doi.org/10.1007/11424529_1},
doi = {10.1007/11424529_1},
abstract = {Predicting the performance of component-based applications is difficult due to the complexity of the underlying component technology. This problem is exacerbated when a messaging protocol is introduced to create a loosely coupled software architecture. Messaging uses asynchronous communication, and must address quality of service issues such as message persistence and flow control. In this paper, we present an approach to predicting the performance of Java 2 Enterprise Edition (J2EE) applications using messaging services. The prediction is done during application design, without access to the application implementation. This is achieved by modeling the interactions among J2EE and messaging components using queuing network models, calibrating the performance model with architecture attributes associated with these components, and populating the model parameters using a lightweight, application-independent benchmark. Benchmarking avoids the need for prototype testing in order to obtain the value of model parameters, and thus reduces the performance prediction effort. A case study is carried out to predict the performance of a J2EE application with asynchronous communication. Analysis of the resulting predictions shows the error is within 15\%.},
booktitle = {Proceedings of the 8th International Conference on Component-Based Software Engineering},
pages = {1–16},
numpages = {16},
location = {St. Louis, MO},
series = {CBSE'05}
}

@inproceedings{10.1145/952532.952584,
author = {Ahn, Gail-Joon and Mohan, Badrinath},
title = {Role-based authorization in decentralized health care environments},
year = {2003},
isbn = {1581136242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/952532.952584},
doi = {10.1145/952532.952584},
abstract = {The formation of a distributed system is based on a collection of distributed components and it requires the ability for components to exchange syntactically well-formed messages. To simplify network programming for such interactions and to realize security services for those components, we need a component-based software architecture that enables software components to communicate directly over a network in a reliable and efficient manner. One of those models is Distributed Component Object Model (DCOM) which is used for interacting with distributed components within the local intranet. In this paper, we overview an aspect of DCOM concerning software architecture and access control. And we describe the concept of role-based access control (RBAC) which began with multi-user and multi-application on-line systems pioneered in the 1970s. Also we investigate how we can enforce the role-based access control as a security provider within the critical environment such as health care industry accessing distributed components legitimately. We demonstrate the feasibility of our approach through a proof-of-concept prototype implementation.},
booktitle = {Proceedings of the 2003 ACM Symposium on Applied Computing},
pages = {251–256},
numpages = {6},
keywords = {authorization, health care envrionments, role-based},
location = {Melbourne, Florida},
series = {SAC '03}
}

@inproceedings{10.1145/3338511.3357348,
author = {Kim, Yongjin and Kim, Evan},
title = {hTPM: Hybrid Implementation of Trusted Platform Module},
year = {2019},
isbn = {9781450368407},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3338511.3357348},
doi = {10.1145/3338511.3357348},
abstract = {Hardware-based TPM provides hardware-backed security solutions and a root of trust for various mission critical applications. However, hardware-based TPM has several intrinsic problems such as extremely low performance, off-chip security vulnerability, and a lack of incident response agility. In the upcoming Quantum computing era, it is critical to provide Quantum-Resistant (QR) cryptography functions without harming performance. Unfortunately, hardware-based TPM's rigid hardware and software architecture model makes it extremely difficult for hardware-based TPM to transition to accommodate future QR cryptographic systems. On the other hand, software-based TPMs (e.g., firmware-based TPM) provide a CPU-based, on-chip security solution. They utilize low-level on-chip primitives offered by chipsets such as ARM TrustZone or Intel Software Guard Extensions (SGX) to build a system with a high-level of trust computing environment. A software-based TPM solution provides higher performance, on-chip security, and incident response agility. However, it is lacking in hardware-backed protection and several vital features such as secure key storage, robustness against side-channel attacks, true random number generation, among others. In addition, its implementation is highly dependent on low-level primitives provided by each hardware vendor, which makes it difficult for it to be provided as a generalized solution. In this paper, we propose hybrid-TPM (hTPM), which fully utilizes the advantages of a hardware-based TPM and diminishes a hardware-based TPM's weaknesses through software-based TPM solutions inside a secure container, e.g., Virtualization-Based Security (VBS).We implemented hTPM as a fully dual mode TPM, i.e., giving end-users full control in choosing between a hardware TPM mode and a software TPM mode based on their needs. We performed and will provide a full risk analysis of the proposed hTPM to show how to best overcome security challenges in realizing hTPM. Finally, we provide a performance analysis of our proposal to show the drastic improvements in cryptographic operations.},
booktitle = {Proceedings of the 1st ACM Workshop on Workshop on Cyber-Security Arms Race},
pages = {3–10},
numpages = {8},
keywords = {key management, quantum-resistance, root of trust, trusted platform module},
location = {London, United Kingdom},
series = {CYSARM'19}
}

@inproceedings{10.1145/1138486.1138494,
author = {Zhu, Liming and Gorton, Ian and Liu, Yan and Bui, Ngoc Bao},
title = {Model driven benchmark generation for web services},
year = {2006},
isbn = {1595933980},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1138486.1138494},
doi = {10.1145/1138486.1138494},
abstract = {Web services solutions are being increasingly adopted in enterprise systems. However, ensuring the quality of service of Web services applications remains a costly and complicated performance engineering task. Some of the new challenges include limited controls over consumers of a service, unforeseeable operational scenarios and vastly different XML payloads. These challenges make existing manual performance analysis and benchmarking methods difficult to use effectively. This paper describes an approach for generating customized benchmark suites for Web services applications from a software architecture description following a Model Driven Architecture (MDA) approach. We have provided a performance-tailored version of the UML 2.0 Testing Profile so architects can model a flexible and reusable load testing architecture, including test data, in a standards compatible way. We extended our MDABench [27] tool to provide a Web service performance testing "cartridge" associated with the tailored testing profile. A load testing suite and automatic performance measurement infrastructure are generated using the new cartridge. Best practices in Web service testing are embodied in the cartridge and inherited by the generated code. This greatly reduces the effort needed for Web service performance benchmarking while being fully MDA compatible. We illustrate the approach using a case study on the Apache Axis platform.},
booktitle = {Proceedings of the 2006 International Workshop on Service-Oriented Software Engineering},
pages = {33–39},
numpages = {7},
keywords = {MDA, code, model-driven development, performance, testing},
location = {Shanghai, China},
series = {SOSE '06}
}

@inproceedings{10.1145/268826.268911,
author = {Holvoet, Tom and Verbaeten, Pierre},
title = {Using agents for simulating and implementing Petri nets},
year = {1997},
isbn = {0818679654},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1145/268826.268911},
doi = {10.1145/268826.268911},
abstract = {This paper presents a software architecture for simulating and implementing Petri nets. It is based on object-oriented techniques and autonomous agents. Object-orientation enables the adaptation and extension of the software architecture with new or alternatively defined features. Agents allow to model a net as a set of autonomous, cooperating entities. The result is a flexible and extendible framework of reusable components for efficiently implementing a large family of Petri net classes.The execution can be performed on a mono-processor, a parallel or distributed system. This is the result of using the XENOOPS execution environments for parallel applications.},
booktitle = {Proceedings of the Eleventh Workshop on Parallel and Distributed Simulation},
pages = {134–137},
numpages = {4},
location = {Lockenhaus, Austria},
series = {PADS '97}
}

@article{10.1145/268823.268911,
author = {Holvoet, Tom and Verbaeten, Pierre},
title = {Using agents for simulating and implementing Petri nets},
year = {1997},
issue_date = {July 1997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {1},
issn = {0163-6103},
url = {https://doi.org/10.1145/268823.268911},
doi = {10.1145/268823.268911},
abstract = {This paper presents a software architecture for simulating and implementing Petri nets. It is based on object-oriented techniques and autonomous agents. Object-orientation enables the adaptation and extension of the software architecture with new or alternatively defined features. Agents allow to model a net as a set of autonomous, cooperating entities. The result is a flexible and extendible framework of reusable components for efficiently implementing a large family of Petri net classes.The execution can be performed on a mono-processor, a parallel or distributed system. This is the result of using the XENOOPS execution environments for parallel applications.},
journal = {SIGSIM Simul. Dig.},
month = jun,
pages = {134–137},
numpages = {4}
}

@inproceedings{10.1145/1071021.1071037,
author = {Israr, Tauseef A. and Lau, Danny H. and Franks, Greg and Woodside, Murray},
title = {Automatic generation of layered queuing software performance models from commonly available traces},
year = {2005},
isbn = {1595930876},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1071021.1071037},
doi = {10.1145/1071021.1071037},
abstract = {Performance models of software designs can give early warnings of problems such as resource saturation or excessive delays. However models are seldom used because of the considerable effort needed to construct them. Software Architecture and Model Extraction (SAME) is a lightweight model building technique that extracts communication patterns from executable designs or prototypes that use message passing, to develop a Layered Queuing Network model in an automated fashion. It is a formal, traceable model building process. The transformation follows a series of well-defined transformation steps, from input domain, (an executable software design or the implementation of software itself) to output domain, a Layered Queuing Network (LQN) Performance model. The SAME technique is appropriate for a message passing distributed system where tasks interact by point-to-point communication. With SAME, the performance analyst can focus on the principles of software performance analysis rather than model building.},
booktitle = {Proceedings of the 5th International Workshop on Software and Performance},
pages = {147–158},
numpages = {12},
keywords = {layered queuing, model building, performance engineering, software performance, tracing performance modeling},
location = {Palma, Illes Balears, Spain},
series = {WOSP '05}
}

@inproceedings{10.1109/CCGrid.2015.73,
author = {Zhao, Zhiming and Taal, Arie and Jones, Andrew and Taylor, Ian and Stankovski, Vlado and Vega, Ignacio Garcia and Hidalgo, Francisco Jesus and Suciu, George and Ulisses, Alexandre and Ferreira, Pedro and de Laat, Cees},
title = {A software workbench for interactive, time critical and highly self-adaptive cloud applications (SWITCH)},
year = {2015},
isbn = {9781479980062},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGrid.2015.73},
doi = {10.1109/CCGrid.2015.73},
abstract = {Time critical applications have very high requirements on network and computing services, in particular on well-tuned software architecture with sophisticated optimisation on data communication. Their development is often customised to dedicated infrastructure, and system performance is difficult to maintain when infrastructure changes. This fatal weakness in existing architecture and software tools causes very high development costs, and makes it difficult to fully utilise the virtualised, programmable and quality-on-demand services provided by networked Clouds to improve the system productivity. The Software Workbench for Interactive, Time Critical and Highly self-adaptive Cloud applications (SWITCH) is a newly funded project by EU H2020 to address this urgent industrial need; it aims at improving the existing development and execution model of time critical applications by introducing a novel conceptual model called application-infrastructure co-programming and control model, in which application QoS/QoE together with the programmability and controllability of Cloud environments can be all included in the complete lifecycle of applications.},
booktitle = {Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing},
pages = {1181–1184},
numpages = {4},
keywords = {cloud, self adaptability, time critical applications},
location = {Shenzhen, China},
series = {CCGRID '15}
}

@inproceedings{10.1145/255471.255639,
author = {Springman, Michael and Richardson, Jeffrey L.},
title = {Command center processing and display system replacement—CCPDS-R},
year = {1990},
isbn = {0897914090},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/255471.255639},
doi = {10.1145/255471.255639},
abstract = {TRW's Ada Process Model, software architecture approach and comprehensive management metrics have been key factors in the success of CCPDS-R, a highly reliable, real-time distributed system with a sophisticated user interface and stringent performance requirements.},
booktitle = {Proceedings of the Conference on TRI-ADA '90},
pages = {623},
location = {Baltimore, Maryland, USA},
series = {TRI-Ada '90}
}

@inproceedings{10.1145/2000259.2000287,
author = {Perez-Palacin, Diego and Mirandola, Raffaela and Merseguer, Jos\'{e}},
title = {Enhancing a QoS-based self-adaptive framework with energy management capabilities},
year = {2011},
isbn = {9781450307246},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2000259.2000287},
doi = {10.1145/2000259.2000287},
abstract = {The energy use is becoming a key design consideration in computing infrastructures and services. In this paper we focus on service-based applications and we propose an adaptation process that can be used to reduce power consumption. This adaptation process is materialized in an adaptation plan which fits into a software architecture specifically designed for self-adaptive systems. The adaptation plan guarantees a trade-off between energy consumption and QoS offered, while maintaining suitable revenues for the service provider. The proposed approach is based on the principle of proportional energy consumption obtained by scaling down energy for unused resources, considering both the number of servers switched on and the operating frequencies of that servers.},
booktitle = {Proceedings of the Joint ACM SIGSOFT Conference -- QoSA and ACM SIGSOFT Symposium -- ISARCS on Quality of Software Architectures -- QoSA and Architecting Critical Systems -- ISARCS},
pages = {165–170},
numpages = {6},
keywords = {energy, performance, software architectures, stochastic petri nets},
location = {Boulder, Colorado, USA},
series = {QoSA-ISARCS '11}
}

@article{10.1145/1113439.1113459,
author = {Belov, Nadya and Koeck, Colin and Krandick, Werner and Shaffer, Joshua},
title = {Mobile mathematics communication},
year = {2005},
issue_date = {September 2005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {39},
number = {3},
issn = {0163-5824},
url = {https://doi.org/10.1145/1113439.1113459},
doi = {10.1145/1113439.1113459},
abstract = {We present a system [1] that allows wireless smartphones to be
used for mathematics communication, that is, for the creation and
exchange of mathematical formulas, diagrams, and text between two
or more participants. The system enables two or more persons with
smartphones or traditional computers to participate in a session.
Each of the participants may convey textual, graphical and
mathematical information to the other participants. Users can draw,
edit, and label geometric shapes, send chat messages, and compose
formulas. A turn taking mechanism moderates the communication. The
system also supports the integration of services that can be used
to provide individual users with additional functionality.
Currently, a LATEX rendering service is available to allow users to
create and share mathematical formulas in typeset quality.Wireless smartphones are becoming the medium of choice for
improvised synchronous collaboration since increasing numbers of
users carry their smartphones at all times. It is true that the
small size of the devices---while necessary for their
ubiquity---limits the complexity of collaborative tasks that can be
carried out effectively. On the other hand, there is a need to
capture inspiration, to access and evaluate information on the go,
and to make decisions on the spot.The domain of mathematics is ideally suited to explore---and
push---the limits of smartphone communication. The challenge of
representing mathematics in typeset form has led to the development
of document preparation systems such as TEX, LATEX, and LYX which
are in widespread use today. Mathematical handwriting recognition
continues to push the limits of general handwriting recognition
[2]. Many of the cognitive challenges that arise in mathematical
collaboration also arise in intellectual teamwork in other
domains.Some of the challenges of developing a system for mobile
mathematics communication are posed by the input and output
limitations of the devices and the enormous heterogeneity of the
available hardware platforms.We use the Treo 600/650 as our hardware platform. Our software
is written in pure Java and can be run on any platform that
supports the Java Virtual Machine. Our software architecture makes
it easy to add new local or remote services to enhance the
communication.The poster presents use-case diagrams, architecture diagrams,
and a series of screenshots that describe the user's interaction
with the system. The poster also shows how we solved the problems
of cross-referencing and turn-taking in mobile collaboration. A
7.5-minute video shows users interacting with the system.},
journal = {SIGSAM Bull.},
month = sep,
pages = {99},
numpages = {1}
}

@inproceedings{10.5555/1266366.1266576,
author = {Gailliard, Gr\'{e}gory and Nicollet, Eric and Sarlotte, Michel and Verdier, Fran\c{c}ois},
title = {Transaction level modelling of SCA compliant software defined radio waveforms and platforms PIM/PSM},
year = {2007},
isbn = {9783981080124},
publisher = {EDA Consortium},
address = {San Jose, CA, USA},
abstract = {In the scope of the US Department of Defense (DoD) Joint Tactical Radio System (JTRS) program, the portability and reconfigurability needs of Software Defined Radios (SDR) required by the Software Communications Architecture (SCA) [1] can be resolved thanks to Model Driven Architecture (MDA) and component/container paradigm to address a heterogeneous hardware and software architecture.In this paper, we propose SystemC Transaction Level Modelling (TLM) to simulate Platform Independent Model (PIM) and Platform Specific Model (PSM) of SDRs, while keeping the component/container approach for applications portability. We show that SystemC 2.1 enables natively to simulate the waveform PIM specified in UML to obtain an executable specification, which can be reused to validate the SystemC TLM model of PSM. This latter allows radio platform virtualisation and true reuse of IPs models to validate earlier SDR waveforms and platforms.},
booktitle = {Proceedings of the Conference on Design, Automation and Test in Europe},
pages = {966–971},
numpages = {6},
location = {Nice, France},
series = {DATE '07}
}

@article{10.1145/140728.140729,
author = {Hac, Anna},
title = {Modeling distributed file systems},
year = {1992},
issue_date = {May 1992},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {0163-5999},
url = {https://doi.org/10.1145/140728.140729},
doi = {10.1145/140728.140729},
abstract = {This paper describes different methods and techniques used to model, analyze, evaluate and implement distributed file systems. Distributed file systems are characterized by the distributed system hardware and software architecture, in which they are implemented as well as by the file systems' functions. In addition, distributed file system performance depends on the load executed in the system. Modeling and analysis of distributed file systems requires new methods to approximate complexity of the system and to provide a useful solution. The complexity of the distributed file system is reflected in the possible placement of the files, file replication, and migration of files and processes. The synchronization mechanisms are needed to control file access. File sharing involves load sharing in distributed environment.},
journal = {SIGMETRICS Perform. Eval. Rev.},
month = may,
pages = {22–27},
numpages = {6}
}

@inproceedings{10.1145/1321211.1321213,
author = {Liu, Sandy and Liang, Yong and Brooks, Martin},
title = {Eucalyptus: a web service-enabled e-infrastructure},
year = {2007},
publisher = {IBM Corp.},
address = {USA},
url = {https://doi.org/10.1145/1321211.1321213},
doi = {10.1145/1321211.1321213},
abstract = {With the support of user configurable high speed networks, the emerging e-Infrastructure allows seamless sharing of expensive scientific resources. These resources are often running on a variety of platforms, have different bandwidth and QoS requirements, require specific configuration by technical experts, and in most cases cannot be accessed through a single point of entry. To address these issues, we propose an extensible, reliable, and simple software architecture to share the applications and resources over hybrid networks, and hide the tools' logistical and provisioning complexities.This paper explores the design and implementation of Eucalyptus, and describes how it leverages the benefits of a Service-oriented Architecture (SoA) to provide a highly adaptable, modular, and loosely coupled solution to configure and manage resources needed by users collaborating over the net. We present our methodology to wrap functions of resources into Web services, and integrate the new Web services into the Eucalyptus platform in a generic way. The streams of the events from these resources are captured. This information is used for monitoring resources' activities and diagnosing any error that may arise. We provide a workflow management service allowing users to orchestrate services based on the description of the resources, their dependencies and the captured streams to perform certain tasks. We also propose a combination of Web services and peer to peer technologies to support users in different communities and different network layers, and to decentralize resource management. Eucalyptus was demonstrated to be effective in assisting architects across multiple sites to effectively participate in a shared design session.},
booktitle = {Proceedings of the 2007 Conference of the Center for Advanced Studies on Collaborative Research},
pages = {1–11},
numpages = {11},
location = {Richmond Hill, Ontario, Canada},
series = {CASCON '07}
}

@inproceedings{10.1145/1028613.1030207,
author = {Wang, Nanbor and Costa, Fabio M. and Corsaro, Angelo and Coulson, Geoffrey and Venkatasubramanian, Nalini and Cerqueira, Renato and Staehli, Richard},
title = {Introduction to the 3rd Workshop on Adaptive and Reflective Middleware (RM2004)},
year = {2004},
isbn = {1581139497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1028613.1030207},
doi = {10.1145/1028613.1030207},
abstract = {IntroductionMost of the middleware used and developed today is characterised by its inﬂexibility in adapting to different target environments and application areas. This lack of adaptability usually comes from the fact that middleware is traditionally built as a single monolithic entity. This inﬂexibility usually can be characterised by either the inability to adapt the behaviour of the platform, the inability to adapt its structure, or even both. In application domains such as mobile computing, distributed multimedia, and distributed real-time and embedded (DRE) systems, where resources are both constrained and variable in time, having the ability to reconﬁgure the middleware in order to optimise the resource usage and/or provide the desired quality of service (QoS) becomes a key feature. Applying reﬂective techniques to middleware in order to open up the implementation is one of the ways to provide a greater degree of conﬁgurability and dynamic adaptability at the middleware level. In the past few years, researchers have been experimenting with the use of reﬂection, component-based software engineering, software architecture design patterns and component frameworks to achieve these goals. Following the success of the past two workshops, the goal of RM2004 is to continue to provide researchers with a leading edge view on the state of the art in reﬂective and adaptive middleware and the challenging problems that remain unsolved. This workshop permits researchers from around the world investigating middleware adaptation to interact and share ideas. It will provide the platform to further the application of adaptive middleware techniques to a variety of domains, such as medicine, command and control, homeland security, entertainment and commerce.This year, the workshop received more papers than did last years workshop. While this is a good indication of the impact this series of workshops has brought to the research community, the number and the high-quality of these submissions have made our job of selecting papers especially diffcult and many good papers had to be turned down. We selected 16 papers out of the 28 submissions. These papers generally fall into 4 major categories of the 4 sessions of the workshop.Componentization: The component-based software development paradigm has become a popular research topics in recent years as it helps developers manage the complexity of building large applications. Topics presented in this session include extending component-based middleware ﬂexibly through an authorization component framework, adaptive component-based middleware, and new model-based software development paradigms which build on the foundation of component-based software.Managing Cross-cutting Concerns: Managing crosscutting concerns is a key issue in building adaptive software systems. Reﬂective and adaptive middleware technologies adopt diﬀerent techniques to manage and coordinate these cross-cutting aspects. Papers in this session discuss these approaches, including applying application-speciﬁc weavers for composing and conﬁguring applications, proﬁling techniques to provide aspects in Java application, using AOP extensions built in the Lua language to conﬁgure CORBA applications, and interoperability between diﬀerent reﬂective systems.Adaptive Communication Paradigms: Adaptive communication remains a key aspect and research issue in re- ﬂective and adaptive middleware. In this session, we review adaptive secure group communication management, run-time adaptation management in mobile and pervasive computing environment, how to address tight-coupling from non-incremental service development, and constructing resource- aware MOM applications.Adaptive Services and Applications: This session case-study of applying reﬂective and adaptive middleware techniques. We will discuss topics including safe distributed service deployment in programmable networks, reviews of past experiences and future research directions, adaptive middleware techniques for ﬂexible data partitioning in parallel computation over space and time domains, and collaborative adaptation among legacy components.AcknowledgementsThe workshop organizers would like to express our thanks to all the program committee members, for their hard work in helping us reviewing the papers. Most importantly, we want to thank all the authors who submitted their papers to the workshop and those who participating in the workshops.},
booktitle = {Proceedings of the 3rd Workshop on Adaptive and Reflective Middleware},
pages = {181},
location = {Toronto, Ontario, Canada},
series = {ARM '04}
}

@proceedings{10.1145/1101516,
title = {ARM '05: Proceedings of the 4th workshop on Reflective and adaptive middleware systems},
year = {2005},
isbn = {1595932704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is a great pleasure to introduce the ACM/IEEE/IFIP Middleware
Workshop Program for Grenoble 2005. This is the fourth time that
Middleware has included a Workshop Program, and the levels of
interest and the standard of submissions continue to be extremely
high. This year we have five workshops. The Workshop on Adaptive
and Reflective Middleware (ARM05) is our most venerable
institution, and is now in its fourth incarnation, having started
out at Middleware 2000 in New York and run at every Middleware
since. Two of the other workshops are also well established, having
run previously in Rio and Toronto. These are the Workshop on
Middleware for Grid Computing (MGC05), and the Workshop on
Middleware for Pervasive and Ad-hoc Computing (MPAC05). MPAC this
year is joined by Didier Donsez and his team whose proposal for a
workshop on 'Middleware for Sensor-Based Services' has been merged
into MPAC. As a consequence, this event is running over two days
rather than the usual one day.Another workshop that is continuing a lively tradition is the
Doctoral Symposium on Middleware. This popular event has worked
particularly well in the past and represents a wonderful
opportunity for young reseachers in our field to present their work
to a mock thesis committee of mentors and to receive valuable and
supportive feeback. This year we also have a new workshop: the 1st
Workshop on Aspect Oriented Middleware Development (AOMD05). This
highlights what seems to be a promising area of synergistic
research that has recently been receiving a lot of attention. We
look forward to a productive dialogue on the relationship between
aspectisation techniques and middleware techniques.Middleware provides a robust and flexible abstraction for
connecting applications together. As connectivity is the major
aspect addressed in middleware, historically middleware is
implemented as monolithic software targeted to specific
environments and application domains. As a result, older middleware
implementations can only perform satisfactorily in their target
enviroments and often can not be used in other types of
applications. This inflexibility can usually be attributed to
middleware implementations' inability to adapt the behaviors or
structure of the platforms to the requirements of changing
environments and application domains.In recent years, researchers have been experimenting with and
applying adaptive and reflective techniques such as reflection,
component-based software engineering, software architecture design
patterns and component frameworks, to extend the application
domains for middleware. The trend can easily be observed in
middleware tailored for large-scale enterprise applications where
diverse infrastructure and applications are becoming common-place.
Similarly, middleware is being applied to new areas such as mobile
computing, distributed multimedia, and distributed real-time and
embedded (DRE) systems, where resources are either constrained or
have changing availability over time. Applying adaptive and
reflective techniques to middleware has shown to provide a greater
degree of configurability and dynamic adaptability for
applications.This is the 4th of a series of workshops on Adaptive and
Reflective Middleware (ARM). Past workshops contributed to the
advancement of middleware research by providing researchers venues
for exchanging leading-edge views and presenting state-of-the-art
studies in the area. Building on the success of past workshops,
this workshop aims to further the application of adaptive and
reflective middleware techniques to a variety of new application
domains, and to support different Quality of Service (QoS)
requirements in middleware.Because of the positive feedback we got from last year's
workshop, we are expanding the panel discussion session. However,
this decision has made paper selection an even harder process
because we were forced to omit many good papers with exciting ideas
from presentation in the workshop program. Fortunately, many
authors of these nice papers gracefully accepted our invitations to
present their work as posters so that we will not miss out on their
good work. For that, the organizing committee would like to express
our sincere gratitude.Papers selected for the workshop program represent the main
thrusts in Adaptive and Reflective Middleware research. They cover
the popular research areas such as aspect and resource management
techniques in ARM using composition and reconfiguration. These
techniques are being applied at various levels in middleware
implementations, from infrastructure design to supporting specific
aspects in the class of applications.},
location = {Grenoble, France}
}